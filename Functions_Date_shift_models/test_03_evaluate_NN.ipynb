{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b47bcb2-08af-4afb-9442-334b8d3ee05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0f6dd5-e65b-4923-b030-ad48d0cc6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine-learning specific imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d3c37b-2934-44dd-b69e-ecc21b8b111e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## API Imports \n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a99553-7b53-496d-874b-93a9f3bae802",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pickle for exports and imports of data  \n",
    "import pickle \n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj, path ):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c7a420-4804-4f78-95c9-d65bc5787bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FMP Constants \n",
    "fmpbase_urlv3 = 'https://fmpcloud.io/api/v3/'\n",
    "fmpbase_urlv4 = 'https://fmpcloud.io/api/v4/'\n",
    "api_key = os.getenv(\"FMP_CLOUD_API_KEY\")\n",
    "\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-01-31'\n",
    "\n",
    "## FMP Functions \n",
    "def get_FMP_historical_data(symbol, startDate=start_date, endDate=end_date, apiKey=api_key):\n",
    "    url_hist_price = fmpbase_urlv3+'historical-price-full/'\n",
    "    url_hist_query_with_date = url_hist_price+symbol+'?from='+startDate+'&to='+endDate+'&apikey='+apiKey\n",
    "    resp_data = requests.get(url_hist_query_with_date)\n",
    "    json_ = resp_data.json()\n",
    "    data = json_['historical']\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={'date':'Date'},inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.reindex(index=df.index[::-1]) ## Reverse the DataFrame \n",
    "    df.set_index('Date',inplace=True)\n",
    "    df.drop(columns='label',inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abd862c-c2c0-4c35-a582-e913132cff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(symbol, n_days):\n",
    "    path = Path('../FilesExport_Complete_DFs_TI_noShift/'+symbol+'_TI_DF_no_shift.pkl')\n",
    "    data = load_obj(path)\n",
    "    df = data[symbol]\n",
    "    \n",
    "    df_close = df[['close']]\n",
    "    df_close = df_close.reset_index().rename(columns={\"Date\": \"Close_Date\"})\n",
    "    \n",
    "    features_df = df.reset_index().drop(columns=['close','adjClose'])\n",
    "    \n",
    "    new_close_df = df_close.iloc[n_days: , :].reset_index(drop=True)\n",
    "    \n",
    "    ## Prevent multiple API calls each time, but use API when needed. \n",
    "    try:\n",
    "        path = Path('../FilesExport_Updated_API_data/'+symbol+'_jan_2022.pkl')\n",
    "        api_df = load_obj(path)\n",
    "    except:\n",
    "        api_df = get_FMP_historical_data(symbol)\n",
    "    \n",
    "\n",
    "    new_data = api_df[['close']]\n",
    "    new_data = new_data.reset_index().rename(columns={\"Date\": \"Close_Date\"})\n",
    "    new_data = new_data.iloc[0:n_days]\n",
    "    \n",
    "    new_close_df = new_close_df.append(new_data, ignore_index=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    return features_df, new_close_df\n",
    "\n",
    "## Dropping QUANTITY_FAILS from dataframe before machine learning \n",
    "\n",
    "def prepare_data_no_FTD(symbol,n_days,return_data=False):\n",
    "    features_df, new_close_df = get_data(symbol,n_days)\n",
    "    \n",
    "    X = features_df.drop(columns={'Date','QUANTITY_FAILS'}).values\n",
    "    y = new_close_df['close'].values\n",
    "    \n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    if return_data == True:\n",
    "        return X, y, features_df, new_close_df\n",
    "    else:\n",
    "        return X, y\n",
    "    \n",
    "def prepare_data(symbol,n_days,return_data=False):\n",
    "    features_df, new_close_df = get_data(symbol,n_days)\n",
    "    \n",
    "    X = features_df.drop(columns='Date').values\n",
    "    y = new_close_df['close'].values\n",
    "    \n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    if return_data == True:\n",
    "        return X, y, features_df, new_close_df\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "add5f611-fbe8-4b98-9147-4c1035a3f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make function that accepts a symbol, and returns 4 dataframes of predicted data, for each model\n",
    "## that can then be used to make plots, etc. \n",
    "\n",
    "def get_prediction_dfs(symbol,n_days,include_model_obj=True):\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    # n_days = 10  ## Has to be 1, 2, 5, or 10 days. \n",
    "    # symbol = 'XRT'\n",
    "    # days_to_plot = 60   ## 23 shows January Data\n",
    "\n",
    "    export_path='../Model_Data/Date_Test_NN_w_FTD_all/High_Acc/'\n",
    "    model_type = 'NN'\n",
    "    n_days_string = str(n_days)\n",
    "    export_path_prefix = export_path+symbol+'_'+model_type+'_'+n_days_string\n",
    "\n",
    "    file_path = Path(export_path_prefix+'_model_data.json')\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    loaded_model1 = model_from_json(model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    file_path = Path(export_path_prefix+'_model_weights.h5')\n",
    "    loaded_model1.load_weights(file_path)\n",
    "\n",
    "    ## Load model summary \n",
    "    file_path = Path(export_path_prefix+'_model_summary.pkl')\n",
    "    model_summary1 = load_obj(file_path)\n",
    "\n",
    "    X1 , y1, features1, close_df1 = prepare_data(symbol,n_days,return_data=True)\n",
    "\n",
    "\n",
    "    close_df1[\"predicted\"] = loaded_model1.predict(X1)\n",
    "    close_df1.set_index('Close_Date',inplace=True)\n",
    "\n",
    "    prediction_df1 = close_df1[['close','predicted']]\n",
    "\n",
    "\n",
    "\n",
    "    export_path='../Model_Data/Date_Test_NN_w_FTD_all/Low_Acc/'\n",
    "    model_type = 'NN'\n",
    "    n_days_string = str(n_days)\n",
    "    export_path_prefix = export_path+symbol+'_'+model_type+'_'+n_days_string\n",
    "\n",
    "    file_path = Path(export_path_prefix+'_model_data.json')\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    loaded_model2 = model_from_json(model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    file_path = Path(export_path_prefix+'_model_weights.h5')\n",
    "    loaded_model2.load_weights(file_path)\n",
    "\n",
    "    ## Load model summary \n",
    "    file_path = Path(export_path_prefix+'_model_summary.pkl')\n",
    "    model_summary2 = load_obj(file_path)\n",
    "\n",
    "    #X2 , y2, features2, close_df2 = prepare_data(symbol,n_days,return_data=True)\n",
    "\n",
    "    close_df1[\"predicted\"] = loaded_model2.predict(X1)\n",
    "    #close_df.set_index('Close_Date',inplace=True) ## Alreayd set above \n",
    "\n",
    "    prediction_df2 = close_df1[['close','predicted']]\n",
    "\n",
    "\n",
    "    export_path='../Model_Data/Date_Test_NN_noFTD_all/High_Acc/'\n",
    "    model_type = 'NN'\n",
    "    n_days_string = str(n_days)\n",
    "    export_path_prefix = export_path+symbol+'_'+model_type+'_'+n_days_string\n",
    "\n",
    "    file_path = Path(export_path_prefix+'_model_data.json')\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    loaded_model3 = model_from_json(model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    file_path = Path(export_path_prefix+'_model_weights.h5')\n",
    "    loaded_model3.load_weights(file_path)\n",
    "\n",
    "    ## Load model summary \n",
    "    file_path = Path(export_path_prefix+'_model_summary.pkl')\n",
    "    model_summary3 = load_obj(file_path)\n",
    "\n",
    "    X2 , y2, features2, close_df2 = prepare_data_no_FTD(symbol,n_days,return_data=True)\n",
    "\n",
    "\n",
    "    close_df2[\"predicted\"] = loaded_model3.predict(X2)\n",
    "    close_df2.set_index('Close_Date',inplace=True)\n",
    "\n",
    "    prediction_df3 = close_df2[['close','predicted']]\n",
    "\n",
    "\n",
    "\n",
    "    export_path='../Model_Data/Date_Test_NN_noFTD_all/Low_Acc/'\n",
    "    model_type = 'NN'\n",
    "    n_days_string = str(n_days)\n",
    "    export_path_prefix = export_path+symbol+'_'+model_type+'_'+n_days_string\n",
    "\n",
    "    file_path = Path(export_path_prefix+'_model_data.json')\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    loaded_model4 = model_from_json(model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    file_path = Path(export_path_prefix+'_model_weights.h5')\n",
    "    loaded_model4.load_weights(file_path)\n",
    "\n",
    "    ## Load model summary \n",
    "    file_path = Path(export_path_prefix+'_model_summary.pkl')\n",
    "    model_summary4 = load_obj(file_path)\n",
    "\n",
    "    #X2 , y2, features2, close_df2 = prepare_data_no_FTD(symbol,n_days,return_data=True)\n",
    "\n",
    "    close_df2[\"predicted\"] = loaded_model4.predict(X2)\n",
    "    #close_df2.set_index('Close_Date',inplace=True)\n",
    "\n",
    "    prediction_df4 = close_df2[['close','predicted']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Instead of returning 4 dataframes, return one big dict containing all data needed \n",
    "    ## for one symbol \n",
    "    \n",
    "    if include_model_obj == True:\n",
    "    \n",
    "        data_dict[symbol] = {\n",
    "            'w_FTD': \n",
    "            {\n",
    "                'model_1': \n",
    "                {\n",
    "                    'loaded_model':loaded_model1,\n",
    "                    'model_summary':model_summary1,\n",
    "                    'prediction_df':prediction_df1,\n",
    "                },\n",
    "                'model_2': \n",
    "                {\n",
    "                    'loaded_model':loaded_model2,\n",
    "                    'model_summary':model_summary2,\n",
    "                    'prediction_df':prediction_df2,\n",
    "                }\n",
    "            },\n",
    "            'woFTD': \n",
    "            {\n",
    "                'model_3': \n",
    "                {\n",
    "                    'loaded_model':loaded_model3,\n",
    "                    'model_summary':model_summary3,\n",
    "                    'prediction_df':prediction_df3,\n",
    "                },\n",
    "                'model_4': \n",
    "                {\n",
    "                    'loaded_model':loaded_model4,\n",
    "                    'model_summary':model_summary4,\n",
    "                    'prediction_df':prediction_df4,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    elif include_model_obj==False:\n",
    "        data_dict[symbol] = {\n",
    "            'w_FTD': \n",
    "            {\n",
    "                'model_1': \n",
    "                {\n",
    "                    #'loaded_model':loaded_model1,\n",
    "                    'model_summary':model_summary1,\n",
    "                    'prediction_df':prediction_df1,\n",
    "                },\n",
    "                'model_2': \n",
    "                {\n",
    "                    #'loaded_model':loaded_model2,\n",
    "                    'model_summary':model_summary2,\n",
    "                    'prediction_df':prediction_df2,\n",
    "                }\n",
    "            },\n",
    "            'woFTD': \n",
    "            {\n",
    "                'model_3': \n",
    "                {\n",
    "                    #'loaded_model':loaded_model3,\n",
    "                    'model_summary':model_summary3,\n",
    "                    'prediction_df':prediction_df3,\n",
    "                },\n",
    "                'model_4': \n",
    "                {\n",
    "                    #'loaded_model':loaded_model4,\n",
    "                    'model_summary':model_summary4,\n",
    "                    'prediction_df':prediction_df4,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4a8d717-96df-4d23-83fd-20411d35397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'AMC'\n",
    "n_days = 10 ## Has to be 1, 2, 5, or 10      ## n_days is the # of days to predict/forecast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96b5cf01-9963-4579-a99b-3a30a5d4a4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMC': {'w_FTD': {'model_1': {'model_summary': {'model_accuracy': 92.69023895263672,\n",
       "     'n_days': 10,\n",
       "     'validation_split_value': 0.1,\n",
       "     'epochs_value': 200},\n",
       "    'prediction_df':                 close  predicted\n",
       "    Close_Date                      \n",
       "    2016-02-17  21.719999  20.683001\n",
       "    2016-02-18  21.690001  20.864908\n",
       "    2016-02-19  21.870001  21.708620\n",
       "    2016-02-22  22.280001  20.226892\n",
       "    2016-02-23  22.040001  19.714796\n",
       "    ...               ...        ...\n",
       "    2022-01-10  22.780000  27.479982\n",
       "    2022-01-11  22.790000  36.298260\n",
       "    2022-01-12  22.720000  33.065479\n",
       "    2022-01-13  20.660000  38.310032\n",
       "    2022-01-14  20.570000  27.662310\n",
       "    \n",
       "    [1491 rows x 2 columns]},\n",
       "   'model_2': {'model_summary': {'model_accuracy': 15.520551681518555,\n",
       "     'n_days': 10,\n",
       "     'validation_split_value': 0.1,\n",
       "     'epochs_value': 200},\n",
       "    'prediction_df':                 close  predicted\n",
       "    Close_Date                      \n",
       "    2016-02-17  21.719999  19.518797\n",
       "    2016-02-18  21.690001  19.587042\n",
       "    2016-02-19  21.870001  20.369421\n",
       "    2016-02-22  22.280001  19.627565\n",
       "    2016-02-23  22.040001  18.508966\n",
       "    ...               ...        ...\n",
       "    2022-01-10  22.780000  22.624681\n",
       "    2022-01-11  22.790000  21.457546\n",
       "    2022-01-12  22.720000  21.648014\n",
       "    2022-01-13  20.660000  22.215700\n",
       "    2022-01-14  20.570000  21.934946\n",
       "    \n",
       "    [1491 rows x 2 columns]}},\n",
       "  'woFTD': {'model_3': {'model_summary': {'model_accuracy': 44.77339172363281,\n",
       "     'n_days': 10,\n",
       "     'validation_split_value': 0.1,\n",
       "     'epochs_value': 200},\n",
       "    'prediction_df':                 close  predicted\n",
       "    Close_Date                      \n",
       "    2016-02-17  21.719999  20.175518\n",
       "    2016-02-18  21.690001  20.450224\n",
       "    2016-02-19  21.870001  21.877657\n",
       "    2016-02-22  22.280001  19.721363\n",
       "    2016-02-23  22.040001  19.710537\n",
       "    ...               ...        ...\n",
       "    2022-01-10  22.780000  35.555008\n",
       "    2022-01-11  22.790000  36.666996\n",
       "    2022-01-12  22.720000  35.352055\n",
       "    2022-01-13  20.660000  38.977345\n",
       "    2022-01-14  20.570000  37.316280\n",
       "    \n",
       "    [1491 rows x 2 columns]},\n",
       "   'model_4': {'model_summary': {'model_accuracy': 17.18129539489746,\n",
       "     'n_days': 10,\n",
       "     'validation_split_value': 0.1,\n",
       "     'epochs_value': 200},\n",
       "    'prediction_df':                 close  predicted\n",
       "    Close_Date                      \n",
       "    2016-02-17  21.719999  20.834093\n",
       "    2016-02-18  21.690001  21.085165\n",
       "    2016-02-19  21.870001  22.070501\n",
       "    2016-02-22  22.280001  20.642141\n",
       "    2016-02-23  22.040001  19.549181\n",
       "    ...               ...        ...\n",
       "    2022-01-10  22.780000  24.796722\n",
       "    2022-01-11  22.790000  24.780863\n",
       "    2022-01-12  22.720000  24.288416\n",
       "    2022-01-13  20.660000  25.531675\n",
       "    2022-01-14  20.570000  25.276735\n",
       "    \n",
       "    [1491 rows x 2 columns]}}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amc_data_dict = get_prediction_dfs(symbol,n_days,include_model_obj=False)\n",
    "amc_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e721c35-4a3a-4132-b715-db2cea575f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
