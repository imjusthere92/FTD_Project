{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf8185e1-6cc3-4318-b99a-8e57f260a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f087fd00-a88b-4715-98c2-0ae0968ab532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine-learning specific imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9c0ca58-346b-43fc-8819-32e71f21f281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## API Imports \n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2776445e-d0c6-4b1c-b66e-7bbbe5beb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pickle for exports and imports of data  \n",
    "import pickle \n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj, path ):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f2296c-e97e-490b-a58d-71867ebb9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FMP Constants \n",
    "fmpbase_urlv3 = 'https://fmpcloud.io/api/v3/'\n",
    "fmpbase_urlv4 = 'https://fmpcloud.io/api/v4/'\n",
    "api_key = os.getenv(\"FMP_CLOUD_API_KEY\")\n",
    "\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-01-31'\n",
    "\n",
    "## FMP Functions \n",
    "def get_FMP_historical_data(symbol, startDate=start_date, endDate=end_date, apiKey=api_key):\n",
    "    url_hist_price = fmpbase_urlv3+'historical-price-full/'\n",
    "    url_hist_query_with_date = url_hist_price+symbol+'?from='+startDate+'&to='+endDate+'&apikey='+apiKey\n",
    "    resp_data = requests.get(url_hist_query_with_date)\n",
    "    json_ = resp_data.json()\n",
    "    data = json_['historical']\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={'date':'Date'},inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.reindex(index=df.index[::-1]) ## Reverse the DataFrame \n",
    "    df.set_index('Date',inplace=True)\n",
    "    df.drop(columns='label',inplace=True)\n",
    "    \n",
    "    ## Export and save data so API calls aren't repeated \n",
    "    path = Path('../FilesExport_Updated_API_data/'+symbol+'_jan_2022.pkl')\n",
    "    save_obj(df,path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ff2d6a-4950-4bc6-a2ef-6d429ba62431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(symbol, n_days):\n",
    "    path = Path('../FilesExport_Complete_DFs_TI_noShift/'+symbol+'_TI_DF_no_shift.pkl')\n",
    "    data = load_obj(path)\n",
    "    df = data[symbol]\n",
    "    \n",
    "    df_close = df[['close']]\n",
    "    df_close = df_close.reset_index().rename(columns={\"Date\": \"Close_Date\"})\n",
    "    \n",
    "    features_df = df.reset_index().drop(columns=['close','adjClose'])\n",
    "    \n",
    "    new_close_df = df_close.iloc[n_days: , :].reset_index(drop=True)\n",
    "    \n",
    "    ## Prevent multiple API calls each time, but use API when needed. \n",
    "    try:\n",
    "        path = Path('../FilesExport_Updated_API_data/'+symbol+'_jan_2022.pkl')\n",
    "        api_df = load_obj(path)\n",
    "    except:\n",
    "        api_df = get_FMP_historical_data(symbol)\n",
    "    \n",
    "\n",
    "    new_data = api_df[['close']]\n",
    "    new_data = new_data.reset_index().rename(columns={\"Date\": \"Close_Date\"})\n",
    "    new_data = new_data.iloc[0:n_days]\n",
    "    \n",
    "    new_close_df = new_close_df.append(new_data, ignore_index=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    return features_df, new_close_df\n",
    "\n",
    "## Dropping QUANTITY_FAILS from dataframe before machine learning \n",
    "\n",
    "def prepare_data(symbol,n_days,return_data=False):\n",
    "    features_df, new_close_df = get_data(symbol,n_days)\n",
    "    \n",
    "    X = features_df.drop(columns={'Date','QUANTITY_FAILS'}).values\n",
    "    y = new_close_df['close'].values\n",
    "    \n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    if return_data == True:\n",
    "        return X, y, features_df, new_close_df\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6777d8-dab0-4576-80c9-03d22aac2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes one symbol and runs model data. \n",
    "## Call function for each individal symbol. No return data.  \n",
    "\n",
    "def mean_squared_model(\n",
    "    symbol,\n",
    "    export_path,  ## Require export path to help avoiding re-writing models \n",
    "    n_days = 5, ## Default value 5, but should be tried with 1-30  \n",
    "    model_count = 5, ## Number of times model runs before saving the best one. \n",
    "    validation_split_value=0.3, ## Default 0.3 for 70/30 split \n",
    "    epochs_value=400,\n",
    "    units1 = 8,\n",
    "    units2 = 8,\n",
    "    num_of_inputs = 20,\n",
    "    num_of_outputs= 1,\n",
    "    model_type = 'NN'\n",
    "    ):    \n",
    "\n",
    "    X, y, = prepare_data(symbol,n_days)\n",
    "    \n",
    "    n_days_string = str(n_days) ## For exporting because can't concat 'int'\n",
    "    accuracy_dict_symbol = str(symbol)+'_'+n_days_string\n",
    "    export_path_prefix_lowAcc = export_path+'Low_Acc/'+symbol+'_'+model_type+'_'+n_days_string \n",
    "    export_path_prefix_highAcc = export_path+'High_Acc/'+symbol+'_'+model_type+'_'+n_days_string \n",
    "\n",
    "\n",
    "    for i in range(model_count):\n",
    "        model_summary = {}\n",
    "        ## Create Neural Network \n",
    "\n",
    "        # Define the model - deep neural network with two layers\n",
    "        nn = Sequential()\n",
    "\n",
    "        # First hidden layer\n",
    "        nn.add(Dense(units=units1, input_dim=num_of_inputs, activation=\"relu\"))\n",
    "\n",
    "        # Second hidden layer\n",
    "        nn.add(Dense(units=units2, activation=\"relu\"))\n",
    "\n",
    "        # Output layer\n",
    "        nn.add(Dense(units=num_of_outputs, activation=\"linear\"))\n",
    "\n",
    "        # Compile the model\n",
    "        nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "        # Fit the model\n",
    "        model = nn.fit(X, y, \n",
    "                          validation_split=validation_split_value, \n",
    "                          epochs=epochs_value, \n",
    "                          verbose=0)\n",
    "            \n",
    "        ## End of if/elif\n",
    "\n",
    "        model_loss, model_accuracy = nn.evaluate(X, y, verbose=0)\n",
    "        \n",
    "        model_summary = {\n",
    "            'model_accuracy':model_accuracy,\n",
    "            'n_days':n_days,\n",
    "            'validation_split_value':validation_split_value,\n",
    "            'epochs_value':epochs_value,\n",
    "                        }\n",
    "        \n",
    "        ## Save first model \n",
    "        if i == 0:\n",
    "            model_accuracy_high = model_accuracy\n",
    "            model_accuracy_low = model_accuracy\n",
    "            \n",
    "            symbol_accuracy_dict[accuracy_dict_symbol] = {\n",
    "                'model_accuracy':model_accuracy,\n",
    "                'n_days':n_days\n",
    "            }\n",
    "            \n",
    "            # Save model data Low_Acc\n",
    "            nn_json = nn.to_json()\n",
    "            file_path = Path(export_path_prefix_lowAcc+'_model_data.json')\n",
    "            with open(file_path, \"w\") as json_file:\n",
    "                json_file.write(nn_json)\n",
    "\n",
    "            # Save weights\n",
    "            file_path = (export_path_prefix_lowAcc+'_model_weights.h5')\n",
    "            nn.save_weights(file_path)\n",
    "            \n",
    "            ## Save model summary \n",
    "            file_path = (export_path_prefix_lowAcc+'_model_summary.pkl')\n",
    "            save_obj(model_summary,file_path)\n",
    "            \n",
    "            # Save model data High_Acc\n",
    "            nn_json = nn.to_json()\n",
    "            file_path = Path(export_path_prefix_highAcc+'_model_data.json')\n",
    "            with open(file_path, \"w\") as json_file:\n",
    "                json_file.write(nn_json)\n",
    "\n",
    "            # Save weights\n",
    "            file_path = (export_path_prefix_highAcc+'_model_weights.h5')\n",
    "            nn.save_weights(file_path)\n",
    "            \n",
    "            ## Save model summary \n",
    "            file_path = (export_path_prefix_highAcc+'_model_summary.pkl')\n",
    "            save_obj(model_summary,file_path)\n",
    "            \n",
    "        ## Rewrite saved model if accuracy better \n",
    "        else:\n",
    "            if model_accuracy < model_accuracy_low:\n",
    "                ## Rewrite values \n",
    "                model_accuracy_low = model_accuracy\n",
    "                symbol_accuracy_dict[accuracy_dict_symbol] = {\n",
    "                    'model_accuracy':model_accuracy,\n",
    "                    'n_days':n_days\n",
    "                }\n",
    "                \n",
    "                # Rewrite saved files\n",
    "                \n",
    "                ## Save model data\n",
    "                nn_json = nn.to_json()\n",
    "                file_path = Path(export_path_prefix_lowAcc+'_model_data.json')\n",
    "                with open(file_path, \"w\") as json_file:\n",
    "                    json_file.write(nn_json)\n",
    "\n",
    "                # Save weights\n",
    "                file_path = (export_path_prefix_lowAcc+'_model_weights.h5')\n",
    "                nn.save_weights(file_path)\n",
    "                \n",
    "                ## Save model summary \n",
    "                file_path = (export_path_prefix_lowAcc+'_model_summary.pkl')\n",
    "                save_obj(model_summary,file_path)\n",
    "                \n",
    "            if model_accuracy > model_accuracy_high:\n",
    "                ## Rewrite values \n",
    "                model_accuracy_high = model_accuracy\n",
    "                symbol_accuracy_dict[accuracy_dict_symbol] = {\n",
    "                    'model_accuracy':model_accuracy,\n",
    "                    'n_days':n_days\n",
    "                }\n",
    "                \n",
    "                # Rewrite saved files\n",
    "                \n",
    "                ## Save model data\n",
    "                nn_json = nn.to_json()\n",
    "                file_path = Path(export_path_prefix_highAcc+'_model_data.json')\n",
    "                with open(file_path, \"w\") as json_file:\n",
    "                    json_file.write(nn_json)\n",
    "\n",
    "                # Save weights\n",
    "                file_path = (export_path_prefix_highAcc+'_model_weights.h5')\n",
    "                nn.save_weights(file_path)\n",
    "                \n",
    "                ## Save model summary \n",
    "                file_path = (export_path_prefix_highAcc+'_model_summary.pkl')\n",
    "                save_obj(model_summary,file_path)\n",
    "    ## End of for loop \n",
    "    ## Return nothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d878cd-e653-4cfa-a9e2-5fc3a6441645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import symbol list \n",
    "path = Path('../Resources/06_01_ML_symbol_success_list.pkl')\n",
    "symbol_list = load_obj(path)\n",
    "len(symbol_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df773475-d4d8-4b27-b6cd-4038a8aaf5b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 149\n  y sizes: 145\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8684/4177032765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m                        \u001b[0mepochs_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                        \u001b[0mvalidation_split_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                        \u001b[0mnum_of_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                       )\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8684/563638951.py\u001b[0m in \u001b[0;36mmean_squared_model\u001b[1;34m(symbol, export_path, n_days, model_count, validation_split_value, epochs_value, units1, units2, num_of_inputs, num_of_outputs, model_type)\u001b[0m\n\u001b[0;32m     47\u001b[0m                           \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                           verbose=0)\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m## End of if/elif\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[0;32m   1656\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 149\n  y sizes: 145\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# ## Create empty dict for accuracy data - only really needed when \n",
    "# ## looping multiple symbols or different models. \n",
    "# symbol_accuracy_dict = {}\n",
    "\n",
    "# for symbol in symbol_list:\n",
    "#     i = 1\n",
    "#     mean_squared_model(symbol,\n",
    "#                        export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "#                        n_days=i,\n",
    "#                        epochs_value=200,\n",
    "#                        validation_split_value=0.1,\n",
    "#                        num_of_inputs=19\n",
    "#                       )\n",
    "#     i = 2\n",
    "#     mean_squared_model(symbol,\n",
    "#                        export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "#                        n_days=i,\n",
    "#                        epochs_value=200,\n",
    "#                        validation_split_value=0.1,\n",
    "#                        num_of_inputs=19\n",
    "#                       )\n",
    "#     i = 5\n",
    "#     mean_squared_model(symbol,\n",
    "#                        export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "#                        n_days=i,\n",
    "#                        epochs_value=200,\n",
    "#                        validation_split_value=0.1,\n",
    "#                        num_of_inputs=19\n",
    "#                       )\n",
    "#     i = 10\n",
    "#     mean_squared_model(symbol,\n",
    "#                        export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "#                        n_days=i,\n",
    "#                        epochs_value=200,\n",
    "#                        validation_split_value=0.1,\n",
    "#                        num_of_inputs=19\n",
    "#                       )\n",
    "\n",
    "# ## Export symbol_accuracy_dict\n",
    "# path = Path('../Resources/NN_noFTDall_symbol_list.pkl')\n",
    "# save_obj(symbol_accuracy_dict,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513dac84-daf4-427d-9003-63cced62aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_accuracy_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8187c75-9a57-41d8-ae55-e966bc1ab589",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EYEG messes up when predicting for n_days = 10 \n",
    "## Adding try loop to code and continuing \n",
    "\n",
    "for index in range(235,len(symbol_list)):\n",
    "    symbol = symbol_list[index] \n",
    "    \n",
    "    try:\n",
    "        i = 1\n",
    "        mean_squared_model(symbol,\n",
    "                           export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "                           n_days=i,\n",
    "                           epochs_value=200,\n",
    "                           validation_split_value=0.1,\n",
    "                           num_of_inputs=19\n",
    "                          )\n",
    "        i = 2\n",
    "        mean_squared_model(symbol,\n",
    "                           export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "                           n_days=i,\n",
    "                           epochs_value=200,\n",
    "                           validation_split_value=0.1,\n",
    "                           num_of_inputs=19\n",
    "                          )\n",
    "        i = 5\n",
    "        mean_squared_model(symbol,\n",
    "                           export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "                           n_days=i,\n",
    "                           epochs_value=200,\n",
    "                           validation_split_value=0.1,\n",
    "                           num_of_inputs=19\n",
    "                          )\n",
    "        i = 10\n",
    "        mean_squared_model(symbol,\n",
    "                           export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "                           n_days=i,\n",
    "                           epochs_value=200,\n",
    "                           validation_split_value=0.1,\n",
    "                           num_of_inputs=19\n",
    "                          )\n",
    "    except: \n",
    "        continue\n",
    "\n",
    "## Export symbol_accuracy_dict\n",
    "path = Path('../Resources/NN_noFTDall_symbol_list.pkl')\n",
    "save_obj(symbol_accuracy_dict,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906440a-8b91-49f1-b9b6-14bf17839e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## load model data \n",
    "# file_path = Path('../Model_Data/Date_Test_NN/'+symbol+'_NN_model_data.json')\n",
    "# with open(file_path, \"r\") as json_file:\n",
    "#     model_json = json_file.read()\n",
    "# loaded_model = model_from_json(model_json)\n",
    "\n",
    "# # load weights into new model\n",
    "# file_path = Path('../Model_Data/Date_Test_NN/'+symbol+'_NN_model_weights.h5')\n",
    "# loaded_model.load_weights(file_path)\n",
    "\n",
    "# # Load model summary\n",
    "# file_path = Path('../Model_Data/Date_Test_NN/'+symbol+'_model_summary.pkl')\n",
    "# model_summary = load_obj(file_path)\n",
    "\n",
    "# X , y, features, close_df = prepare_data(symbol,n_days,return_data=True)\n",
    "\n",
    "\n",
    "# close_df[\"predicted\"] = loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfcfee-563c-4482-8972-8ac5dab775c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_path='../Model_Data/Date_Test_NN/'\n",
    "# model_type = 'NN'\n",
    "\n",
    "# model_summary_list = [] \n",
    "\n",
    "# for i in range(1,11):\n",
    "#     # Load model summary\n",
    "#     n_days_string = str(i)\n",
    "#     file_path = Path('_model_summary.pkl')\n",
    "#     model_summary = load_obj(file_path)\n",
    "    \n",
    "#     model_summary_list.append(model_summary)\n",
    "# model_summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f37643-37dc-4d5c-8905-afa3fef1bbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0b072-fde5-49ea-94fc-d4f0aa0cf42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_days = 1\n",
    "# model_type = 'NN'\n",
    "\n",
    "# export_path='../Model_Data/Date_Test_NN_noFTD/'\n",
    "# export_path_prefix = export_path+symbol+'_'+model_type+'_'+n_days_string\n",
    "# n_days_string = str(n_days)\n",
    "\n",
    "# file_path = Path(export_path_prefix+'_model_data.json')\n",
    "# with open(file_path, \"r\") as json_file:\n",
    "#     model_json = json_file.read()\n",
    "# loaded_model = model_from_json(model_json)\n",
    "\n",
    "# # load weights into new model\n",
    "# file_path = Path(export_path_prefix+'_model_weights.h5')\n",
    "# loaded_model.load_weights(file_path)\n",
    "\n",
    "# X , y, features, close_df = prepare_data(symbol,n_days,return_data=True)\n",
    "\n",
    "\n",
    "# close_df[\"predicted\"] = loaded_model.predict(X)\n",
    "# close_df.set_index('Close_Date',inplace=True)\n",
    "# close_df[['close','predicted']].tail(30).plot(use_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d488c0d-3d5a-4c6e-b9c9-4b8ad4fe7231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612a318-9792-4ef4-864d-6f35d65b5ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
