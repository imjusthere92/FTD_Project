{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8185e1-6cc3-4318-b99a-8e57f260a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f087fd00-a88b-4715-98c2-0ae0968ab532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine-learning specific imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9c0ca58-346b-43fc-8819-32e71f21f281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## API Imports \n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2776445e-d0c6-4b1c-b66e-7bbbe5beb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pickle for exports and imports of data  \n",
    "import pickle \n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj, path ):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f2296c-e97e-490b-a58d-71867ebb9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FMP Constants \n",
    "fmpbase_urlv3 = 'https://fmpcloud.io/api/v3/'\n",
    "fmpbase_urlv4 = 'https://fmpcloud.io/api/v4/'\n",
    "api_key = os.getenv(\"FMP_CLOUD_API_KEY\")\n",
    "\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-01-31'\n",
    "\n",
    "## FMP Functions \n",
    "def get_FMP_historical_data(symbol, startDate=start_date, endDate=end_date, apiKey=api_key):\n",
    "    url_hist_price = fmpbase_urlv3+'historical-price-full/'\n",
    "    url_hist_query_with_date = url_hist_price+symbol+'?from='+startDate+'&to='+endDate+'&apikey='+apiKey\n",
    "    resp_data = requests.get(url_hist_query_with_date)\n",
    "    json_ = resp_data.json()\n",
    "    data = json_['historical']\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={'date':'Date'},inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.reindex(index=df.index[::-1]) ## Reverse the DataFrame \n",
    "    df.set_index('Date',inplace=True)\n",
    "    df.drop(columns='label',inplace=True)\n",
    "    \n",
    "    ## Export and save data so API calls aren't repeated \n",
    "    path = Path('../FilesExport_Updated_API_data/'+symbol+'_jan_2022.pkl')\n",
    "    save_obj(df,path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ff2d6a-4950-4bc6-a2ef-6d429ba62431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(symbol, n_days):\n",
    "    path = Path('../FilesExport_Complete_DFs_TI_noShift/'+symbol+'_TI_DF_no_shift.pkl')\n",
    "    data = load_obj(path)\n",
    "    df = data[symbol]\n",
    "    \n",
    "    df_close = df[['close']]\n",
    "    df_close = df_close.reset_index().rename(columns={\"Date\": \"Close_Date\"})\n",
    "    \n",
    "    features_df = df.reset_index().drop(columns=['close','adjClose'])\n",
    "    \n",
    "    new_close_df = df_close.iloc[n_days: , :].reset_index(drop=True)\n",
    "    \n",
    "    ## Prevent multiple API calls each time, but use API when needed. \n",
    "    try:\n",
    "        path = Path('../FilesExport_Updated_API_data/'+symbol+'_jan_2022.pkl')\n",
    "        api_df = load_obj(path)\n",
    "    except:\n",
    "        api_df = get_FMP_historical_data(symbol)\n",
    "    \n",
    "\n",
    "    new_data = api_df[['close']]\n",
    "    new_data = new_data.reset_index().rename(columns={\"Date\": \"Close_Date\"})\n",
    "    new_data = new_data.iloc[0:n_days]\n",
    "    \n",
    "    new_close_df = new_close_df.append(new_data, ignore_index=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    return features_df, new_close_df\n",
    "\n",
    "## Dropping QUANTITY_FAILS from dataframe before machine learning \n",
    "\n",
    "def prepare_data(symbol,n_days,return_data=False):\n",
    "    features_df, new_close_df = get_data(symbol,n_days)\n",
    "    \n",
    "    X = features_df.drop(columns={'Date','QUANTITY_FAILS'}).values\n",
    "    y = new_close_df['close'].values\n",
    "    \n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    if return_data == True:\n",
    "        return X, y, features_df, new_close_df\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6777d8-dab0-4576-80c9-03d22aac2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes one symbol and runs model data. \n",
    "## Call function for each individal symbol. No return data.  \n",
    "\n",
    "def mean_squared_model(\n",
    "    symbol,\n",
    "    export_path,  ## Require export path to help avoiding re-writing models \n",
    "    n_days = 5, ## Default value 5, but should be tried with 1-30  \n",
    "    model_count = 5, ## Number of times model runs before saving the best one. \n",
    "    validation_split_value=0.3, ## Default 0.3 for 70/30 split \n",
    "    epochs_value=400,\n",
    "    units1 = 8,\n",
    "    units2 = 8,\n",
    "    num_of_inputs = 20,\n",
    "    num_of_outputs= 1,\n",
    "    model_type = 'NN'\n",
    "    ):    \n",
    "\n",
    "    X, y, = prepare_data(symbol,n_days)\n",
    "    \n",
    "    n_days_string = str(n_days) ## For exporting because can't concat 'int'\n",
    "    accuracy_dict_symbol = str(symbol)+'_'+n_days_string\n",
    "    export_path_prefix_lowAcc = export_path+'Low_Acc/'+symbol+'_'+model_type+'_'+n_days_string \n",
    "    export_path_prefix_highAcc = export_path+'High_Acc/'+symbol+'_'+model_type+'_'+n_days_string \n",
    "\n",
    "\n",
    "    for i in range(model_count):\n",
    "        model_summary = {}\n",
    "        ## Create Neural Network \n",
    "\n",
    "        # Define the model - deep neural network with two layers\n",
    "        nn = Sequential()\n",
    "\n",
    "        # First hidden layer\n",
    "        nn.add(Dense(units=units1, input_dim=num_of_inputs, activation=\"relu\"))\n",
    "\n",
    "        # Second hidden layer\n",
    "        nn.add(Dense(units=units2, activation=\"relu\"))\n",
    "\n",
    "        # Output layer\n",
    "        nn.add(Dense(units=num_of_outputs, activation=\"linear\"))\n",
    "\n",
    "        # Compile the model\n",
    "        nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "        # Fit the model\n",
    "        model = nn.fit(X, y, \n",
    "                          validation_split=validation_split_value, \n",
    "                          epochs=epochs_value, \n",
    "                          verbose=0)\n",
    "            \n",
    "        ## End of if/elif\n",
    "\n",
    "        model_loss, model_accuracy = nn.evaluate(X, y, verbose=0)\n",
    "        \n",
    "        model_summary = {\n",
    "            'model_accuracy':model_accuracy,\n",
    "            'n_days':n_days,\n",
    "            'validation_split_value':validation_split_value,\n",
    "            'epochs_value':epochs_value,\n",
    "                        }\n",
    "        \n",
    "        ## Save first model \n",
    "        if i == 0:\n",
    "            model_accuracy_ = model_accuracy\n",
    "            symbol_accuracy_dict[accuracy_dict_symbol] = {\n",
    "                'model_accuracy':model_accuracy,\n",
    "                'n_days':n_days\n",
    "            }\n",
    "            \n",
    "            # Save model data Low_Acc\n",
    "            nn_json = nn.to_json()\n",
    "            file_path = Path(export_path_prefix_lowAcc+'_model_data.json')\n",
    "            with open(file_path, \"w\") as json_file:\n",
    "                json_file.write(nn_json)\n",
    "\n",
    "            # Save weights\n",
    "            file_path = (export_path_prefix_lowAcc+'_model_weights.h5')\n",
    "            nn.save_weights(file_path)\n",
    "            \n",
    "            ## Save model summary \n",
    "            file_path = (export_path_prefix_lowAcc+'_model_summary.pkl')\n",
    "            save_obj(model_summary,file_path)\n",
    "            \n",
    "            # Save model data High_Acc\n",
    "            nn_json = nn.to_json()\n",
    "            file_path = Path(export_path_prefix_highAcc+'_model_data.json')\n",
    "            with open(file_path, \"w\") as json_file:\n",
    "                json_file.write(nn_json)\n",
    "\n",
    "            # Save weights\n",
    "            file_path = (export_path_prefix_highAcc+'_model_weights.h5')\n",
    "            nn.save_weights(file_path)\n",
    "            \n",
    "            ## Save model summary \n",
    "            file_path = (export_path_prefix_highAcc+'_model_summary.pkl')\n",
    "            save_obj(model_summary,file_path)\n",
    "            \n",
    "        ## Rewrite saved model if accuracy better \n",
    "        else:\n",
    "            if model_accuracy < model_accuracy_:\n",
    "                ## Rewrite values \n",
    "                model_accuracy_ = model_accuracy\n",
    "                symbol_accuracy_dict[accuracy_dict_symbol] = {\n",
    "                    'model_accuracy':model_accuracy,\n",
    "                    'n_days':n_days\n",
    "                }\n",
    "                \n",
    "                # Rewrite saved files\n",
    "                \n",
    "                ## Save model data\n",
    "                nn_json = nn.to_json()\n",
    "                file_path = Path(export_path_prefix_lowAcc+'_model_data.json')\n",
    "                with open(file_path, \"w\") as json_file:\n",
    "                    json_file.write(nn_json)\n",
    "\n",
    "                # Save weights\n",
    "                file_path = (export_path_prefix_lowAcc+'_model_weights.h5')\n",
    "                nn.save_weights(file_path)\n",
    "                \n",
    "                ## Save model summary \n",
    "                file_path = (export_path_prefix_lowAcc+'_model_summary.pkl')\n",
    "                save_obj(model_summary,file_path)\n",
    "                \n",
    "            if model_accuracy > model_accuracy_:\n",
    "                ## Rewrite values \n",
    "                model_accuracy_ = model_accuracy\n",
    "                symbol_accuracy_dict[accuracy_dict_symbol] = {\n",
    "                    'model_accuracy':model_accuracy,\n",
    "                    'n_days':n_days\n",
    "                }\n",
    "                \n",
    "                # Rewrite saved files\n",
    "                \n",
    "                ## Save model data\n",
    "                nn_json = nn.to_json()\n",
    "                file_path = Path(export_path_prefix_highAcc+'_model_data.json')\n",
    "                with open(file_path, \"w\") as json_file:\n",
    "                    json_file.write(nn_json)\n",
    "\n",
    "                # Save weights\n",
    "                file_path = (export_path_prefix_highAcc+'_model_weights.h5')\n",
    "                nn.save_weights(file_path)\n",
    "                \n",
    "                ## Save model summary \n",
    "                file_path = (export_path_prefix_highAcc+'_model_summary.pkl')\n",
    "                save_obj(model_summary,file_path)\n",
    "    ## End of for loop \n",
    "    ## Return nothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d878cd-e653-4cfa-a9e2-5fc3a6441645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import symbol list \n",
    "path = Path('../Resources/06_01_ML_symbol_success_list.pkl')\n",
    "symbol_list = load_obj(path)\n",
    "len(symbol_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df773475-d4d8-4b27-b6cd-4038a8aaf5b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20496/2944817526.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                            \u001b[0mepochs_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                            \u001b[0mvalidation_split_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                            \u001b[0mnum_of_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                           )\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20496/3161581362.py\u001b[0m in \u001b[0;36mmean_squared_model\u001b[1;34m(symbol, export_path, n_days, model_count, validation_split_value, epochs_value, units1, units2, num_of_inputs, num_of_outputs, model_type)\u001b[0m\n\u001b[0;32m     57\u001b[0m                           \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                           verbose=0)\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m## End of if/elif\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1261\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1263\u001b[1;33m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[0;32m   1264\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3131\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3133\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1960\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    604\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 59\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Create empty dict for accuracy data - only really needed when \n",
    "## looping multiple symbols or different models. \n",
    "symbol_accuracy_dict = {}\n",
    "\n",
    "for symbol in symbol_list:\n",
    "    i = 1\n",
    "    mean_squared_model(symbol,\n",
    "                       export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "                       n_days=i,\n",
    "                       epochs_value=200,\n",
    "                       validation_split_value=0.1,\n",
    "                       num_of_inputs=19\n",
    "                      )\n",
    "    i = 2\n",
    "    mean_squared_model(symbol,\n",
    "                       export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "                       n_days=i,\n",
    "                       epochs_value=200,\n",
    "                       validation_split_value=0.1,\n",
    "                       num_of_inputs=19\n",
    "                      )\n",
    "    i = 5\n",
    "    mean_squared_model(symbol,\n",
    "                       export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "                       n_days=i,\n",
    "                       epochs_value=200,\n",
    "                       validation_split_value=0.1,\n",
    "                       num_of_inputs=19\n",
    "                      )\n",
    "    i = 10\n",
    "    mean_squared_model(symbol,\n",
    "                       export_path='../Model_Data/Date_Test_NN_noFTD_all/',\n",
    "                       n_days=i,\n",
    "                       epochs_value=200,\n",
    "                       validation_split_value=0.1,\n",
    "                       num_of_inputs=19\n",
    "                      )\n",
    "\n",
    "## Export symbol_accuracy_dict\n",
    "path = Path('../Resources/NN_noFTDall_symbol_list.pkl')\n",
    "save_obj(symbol_accuracy_dict,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513dac84-daf4-427d-9003-63cced62aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_accuracy_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906440a-8b91-49f1-b9b6-14bf17839e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## load model data \n",
    "# file_path = Path('../Model_Data/Date_Test_NN/'+symbol+'_NN_model_data.json')\n",
    "# with open(file_path, \"r\") as json_file:\n",
    "#     model_json = json_file.read()\n",
    "# loaded_model = model_from_json(model_json)\n",
    "\n",
    "# # load weights into new model\n",
    "# file_path = Path('../Model_Data/Date_Test_NN/'+symbol+'_NN_model_weights.h5')\n",
    "# loaded_model.load_weights(file_path)\n",
    "\n",
    "# # Load model summary\n",
    "# file_path = Path('../Model_Data/Date_Test_NN/'+symbol+'_model_summary.pkl')\n",
    "# model_summary = load_obj(file_path)\n",
    "\n",
    "# X , y, features, close_df = prepare_data(symbol,n_days,return_data=True)\n",
    "\n",
    "\n",
    "# close_df[\"predicted\"] = loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfcfee-563c-4482-8972-8ac5dab775c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_path='../Model_Data/Date_Test_NN/'\n",
    "# model_type = 'NN'\n",
    "\n",
    "# model_summary_list = [] \n",
    "\n",
    "# for i in range(1,11):\n",
    "#     # Load model summary\n",
    "#     n_days_string = str(i)\n",
    "#     file_path = Path('_model_summary.pkl')\n",
    "#     model_summary = load_obj(file_path)\n",
    "    \n",
    "#     model_summary_list.append(model_summary)\n",
    "# model_summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f37643-37dc-4d5c-8905-afa3fef1bbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0b072-fde5-49ea-94fc-d4f0aa0cf42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_days = 1\n",
    "# model_type = 'NN'\n",
    "\n",
    "# export_path='../Model_Data/Date_Test_NN_noFTD/'\n",
    "# export_path_prefix = export_path+symbol+'_'+model_type+'_'+n_days_string\n",
    "# n_days_string = str(n_days)\n",
    "\n",
    "# file_path = Path(export_path_prefix+'_model_data.json')\n",
    "# with open(file_path, \"r\") as json_file:\n",
    "#     model_json = json_file.read()\n",
    "# loaded_model = model_from_json(model_json)\n",
    "\n",
    "# # load weights into new model\n",
    "# file_path = Path(export_path_prefix+'_model_weights.h5')\n",
    "# loaded_model.load_weights(file_path)\n",
    "\n",
    "# X , y, features, close_df = prepare_data(symbol,n_days,return_data=True)\n",
    "\n",
    "\n",
    "# close_df[\"predicted\"] = loaded_model.predict(X)\n",
    "# close_df.set_index('Close_Date',inplace=True)\n",
    "# close_df[['close','predicted']].tail(30).plot(use_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d488c0d-3d5a-4c6e-b9c9-4b8ad4fe7231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612a318-9792-4ef4-864d-6f35d65b5ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
