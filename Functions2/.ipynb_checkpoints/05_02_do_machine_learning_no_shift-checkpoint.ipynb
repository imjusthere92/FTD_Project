{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce016ac-22af-4847-9038-de30fc1d87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "734d24d7-10ab-4783-8f50-a330558e8d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine-learning specific imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548c9350-4bbe-469e-8619-b85d63e72347",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pickle for exports and imports of data  \n",
    "import pickle \n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj, path ):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ede2219-373e-40c7-bd64-3d0c1dc8a0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import symbol list \n",
    "path = Path('../Resources/list_TI_export_success.pkl')\n",
    "key_list = load_obj(path)\n",
    "len(key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94210e93-f08f-4ee9-95a3-af5837f25883",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes one symbol and runs model data. \n",
    "## Call function for each individal symbol. No return data.  \n",
    "\n",
    "def mean_squared_model(\n",
    "    symbol,\n",
    "    model_count = 9, ## Number of times model runs before saving the best one. Should be multiple of 3\n",
    "    validation_split_value=0.3,\n",
    "    epochs_value=400,\n",
    "    units1 = 8,\n",
    "    units2 = 8,\n",
    "    units3 = 4,\n",
    "    ):\n",
    "    \n",
    "    key = symbol \n",
    "    path = Path('../FilesExport_DFs_with_TI_pkl/'+key+'_data_dict_with_technicals.pkl')\n",
    "      \n",
    "    data = load_obj(path)\n",
    "    import_df = data[key]\n",
    "    df = import_df.copy()\n",
    "    #data_dict[key] = df\n",
    "        \n",
    "    X = df.drop(columns={'close','adjClose'}).values\n",
    "    y = df['close'].values\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)    \n",
    "    \n",
    "    num_of_inputs = 20\n",
    "    num_of_outputs= 1\n",
    "    layers = 1 ## Run the first model with one layer \n",
    "\n",
    "    for i in range(model_count):\n",
    "        ## Create Neural Network \n",
    "        if layers == 1:\n",
    "            # Create a shallow, 1 hidden layer, neural network\n",
    "            nn = Sequential()\n",
    "\n",
    "            # Hidden layer\n",
    "            nn.add(Dense(units=units1, input_dim=num_of_inputs, activation=\"relu\"))\n",
    "\n",
    "            # Output layer\n",
    "            nn.add(Dense(units=num_of_outputs, activation=\"linear\"))\n",
    "\n",
    "            # Compile the model\n",
    "            nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "            # Fit the model\n",
    "            model = nn.fit(X, y, \n",
    "                              validation_split=validation_split_value, \n",
    "                              epochs=epochs_value,\n",
    "                              verbose=0)\n",
    "            layers = 2 ## Run again with two layers \n",
    "            \n",
    "        elif layers == 2:\n",
    "            # Define the model - deep neural network with two layers\n",
    "            nn = Sequential()\n",
    "\n",
    "            # First hidden layer\n",
    "            nn.add(Dense(units=units1, input_dim=num_of_inputs, activation=\"relu\"))\n",
    "\n",
    "            # Second hidden layer\n",
    "            nn.add(Dense(units=units2, activation=\"relu\"))\n",
    "\n",
    "            # Output layer\n",
    "            nn.add(Dense(units=num_of_outputs, activation=\"linear\"))\n",
    "\n",
    "            # Compile the model\n",
    "            nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "            # Fit the model\n",
    "            model = nn.fit(X, y, \n",
    "                              validation_split=validation_split_value, \n",
    "                              epochs=epochs_value, \n",
    "                              verbose=0)\n",
    "            layers = 3 ## Run again with three layers \n",
    "            \n",
    "        elif layers == 3:\n",
    "            # Define the model - deep neural network with two layers\n",
    "            nn = Sequential()\n",
    "\n",
    "            # First hidden layer\n",
    "            nn.add(Dense(units=units1, input_dim=num_of_inputs, activation=\"relu\"))\n",
    "\n",
    "            # Second hidden layer\n",
    "            nn.add(Dense(units=units2, activation=\"relu\"))\n",
    "            \n",
    "            # Third hidden layer\n",
    "            nn.add(Dense(units=units3, activation=\"relu\"))\n",
    "\n",
    "            # Output layer\n",
    "            nn.add(Dense(units=num_of_outputs, activation=\"linear\"))\n",
    "\n",
    "            # Compile the model\n",
    "            nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "            # Fit the model\n",
    "            model = nn.fit(X, y, \n",
    "                              validation_split=validation_split_value, \n",
    "                              epochs=epochs_value, \n",
    "                              verbose=0)\n",
    "            layers = 1 ## Go back to 1 layer and re-run \n",
    "        ## End of if/elif\n",
    "\n",
    "        model_loss, model_accuracy = nn.evaluate(X, y, verbose=0)\n",
    "        \n",
    "        ## Save first model \n",
    "        if i == 0:\n",
    "            model_accuracy_high= model_accuracy\n",
    "            model_accuracy_low = model_accuracy\n",
    "            symbol_accuracy_dict_high[symbol] = model_accuracy_high\n",
    "            symbol_accuracy_dict_low[symbol] = model_accuracy_low\n",
    "            # Save model as JSON\n",
    "            nn_json = nn.to_json()\n",
    "\n",
    "            file_path = Path('../Model_Data_high_acc/'+symbol+'_model_data.json')\n",
    "            with open(file_path, \"w\") as json_file:\n",
    "                json_file.write(nn_json)\n",
    "\n",
    "            # Save weights\n",
    "            file_path = ('../Model_Data_high_acc/'+symbol+'_model_weights.h5')\n",
    "            nn.save_weights(file_path)\n",
    "            \n",
    "            file_path = Path('../Model_Data_low_acc/'+symbol+'_model_data.json')\n",
    "            with open(file_path, \"w\") as json_file:\n",
    "                json_file.write(nn_json)\n",
    "\n",
    "            # Save weights\n",
    "            file_path = ('../Model_Data_low_acc/'+symbol+'_model_weights.h5')\n",
    "        ## Rewrite saved model if accuracy is higher or lower \n",
    "        else:\n",
    "            if model_accuracy > model_accuracy_high:\n",
    "                ## Rewrite values \n",
    "                model_accuracy_high = model_accuracy\n",
    "                symbol_accuracy_dict_high[symbol] = model_accuracy_high\n",
    "                \n",
    "                ## Rewrite saved files \n",
    "                nn_json = nn.to_json()\n",
    "\n",
    "                file_path = Path('../Model_Data_high_acc/'+symbol+'_model_data.json')\n",
    "                with open(file_path, \"w\") as json_file:\n",
    "                    json_file.write(nn_json)\n",
    "\n",
    "                # Save weights\n",
    "                file_path = ('../Model_Data_high_acc/'+symbol+'_model_weights.h5')\n",
    "                nn.save_weights(file_path)\n",
    "            elif model_accuracy < model_accuracy_low:\n",
    "                ## Rewrite values \n",
    "                model_accuracy_low = model_accuracy\n",
    "                symbol_accuracy_dict_low[symbol] = model_accuracy_low\n",
    "                \n",
    "                # Rewrite saved files \n",
    "                nn_json = nn.to_json()\n",
    "\n",
    "                file_path = Path('../Model_Data_low_acc/'+symbol+'_model_data.json')\n",
    "                with open(file_path, \"w\") as json_file:\n",
    "                    json_file.write(nn_json)\n",
    "\n",
    "                # Save weights\n",
    "                file_path = ('../Model_Data_low_acc/'+symbol+'_model_weights.h5')\n",
    "                nn.save_weights(file_path)\n",
    "    ## End of for loop \n",
    "    ## Return nothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb27c43a-d1d4-4937-a270-a25dcd940331",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create empty dicts for accuracy data \n",
    "symbol_accuracy_dict_low = {}\n",
    "symbol_accuracy_dict_high = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282cc1e2-f10d-4923-a023-0dc3070f86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run test model \n",
    "# mean_squared_model('GME',model_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2335fd46-12cc-4507-aeea-5231649ef139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-02</th>\n",
       "      <td>25.920000</td>\n",
       "      <td>25.853542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-03</th>\n",
       "      <td>26.170000</td>\n",
       "      <td>25.727924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-04</th>\n",
       "      <td>27.010000</td>\n",
       "      <td>26.741894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-05</th>\n",
       "      <td>26.830000</td>\n",
       "      <td>26.736399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-08</th>\n",
       "      <td>27.889999</td>\n",
       "      <td>27.769981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>173.970000</td>\n",
       "      <td>114.554626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>177.840000</td>\n",
       "      <td>116.913857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>173.510000</td>\n",
       "      <td>114.011879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-28</th>\n",
       "      <td>182.850000</td>\n",
       "      <td>112.868515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-29</th>\n",
       "      <td>183.510000</td>\n",
       "      <td>108.880547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1448 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 close   predicted\n",
       "Date                              \n",
       "2016-02-02   25.920000   25.853542\n",
       "2016-02-03   26.170000   25.727924\n",
       "2016-02-04   27.010000   26.741894\n",
       "2016-02-05   26.830000   26.736399\n",
       "2016-02-08   27.889999   27.769981\n",
       "...                ...         ...\n",
       "2021-10-25  173.970000  114.554626\n",
       "2021-10-26  177.840000  116.913857\n",
       "2021-10-27  173.510000  114.011879\n",
       "2021-10-28  182.850000  112.868515\n",
       "2021-10-29  183.510000  108.880547\n",
       "\n",
       "[1448 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Code to load model and do predictions \n",
    "\n",
    "## Set Symbol \n",
    "symbol = 'GME'\n",
    "\n",
    "# load json and create model\n",
    "file_path = Path('../Model_Data_high_acc/'+symbol+'_model_data.json')\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "loaded_model = model_from_json(model_json)\n",
    "\n",
    "# load weights into new model\n",
    "file_path = Path('../Model_Data_high_acc/'+symbol+'_model_weights.h5')\n",
    "loaded_model.load_weights(file_path)\n",
    "\n",
    "## Need to load data to apply to model \n",
    "key = symbol \n",
    "path = Path('../FilesExport_DFs_with_TI_pkl/'+key+'_data_dict_with_technicals.pkl')\n",
    "data = load_obj(path)\n",
    "import_df = data[key]\n",
    "df = import_df.copy()\n",
    "\n",
    "## Set X and y data and scale \n",
    "X = df.drop(columns={'close','adjClose'}).values\n",
    "y = df['close'].values\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X) \n",
    "\n",
    "## Copy dataframe and apply to model \n",
    "df2 = df.copy()\n",
    "df2[\"predicted\"] = loaded_model.predict(X)\n",
    "df_pred = df2[['close','predicted']]\n",
    "\n",
    "df_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e183fd-2ed1-47f7-8add-5ddd5d7c0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_key_list = key_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8040d66-57d5-4f7f-938b-fe1970ad7dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAA\n",
      "AAL\n",
      "AAOI\n",
      "AAU\n",
      "AAXJ\n",
      "ABUS\n",
      "ACB\n",
      "ACER\n",
      "ACOR\n",
      "ACRS\n"
     ]
    }
   ],
   "source": [
    "for key in test_key_list:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6a678-8c07-4c04-b8b9-222da3a47f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in test_key_list:\n",
    "    mean_squared_model(key,model_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ee07e-f4ae-4656-8e73-52a3d853a4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
