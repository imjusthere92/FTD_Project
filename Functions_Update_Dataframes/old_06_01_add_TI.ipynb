{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db371bb2-546a-4939-b671-3cf9841aae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite to add TI indicators to symbols from machine_learning_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68bc5275-9187-460b-b85e-d6faadfe5d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import requests\n",
    "import json\n",
    "# import hvplot.pandas\n",
    "# from dotenv import load_dotenv\n",
    "from datetime import date\n",
    "import os\n",
    "from scipy import stats\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from numpy.lib import pad\n",
    "#import pad\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4c81db-5fb2-4f3b-8e50-132c6f3ae4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pickle for exports and imports of data  \n",
    "import pickle \n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj, path ):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88105f2-1f0e-411b-87a6-9ccd5418c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_spearman(seqa, seqb, window):\n",
    "    stridea = seqa.values.strides[0]\n",
    "    ssa = as_strided(seqa, shape=[len(seqa) - window + 1, window], strides=[stridea, stridea])\n",
    "    strideb = seqa.values.strides[0]\n",
    "    ssb = as_strided(seqb, shape=[len(seqb) - window + 1, window], strides =[strideb, strideb])\n",
    "    ar = pd.DataFrame(ssa)\n",
    "    br = pd.DataFrame(ssb)\n",
    "    ar = ar.rank(1)\n",
    "    br = br.rank(1)\n",
    "    corrs = ar.corrwith(br, 1)\n",
    "    return pad(corrs, (window - 1, 0), 'constant', constant_values=np.nan)\n",
    "\n",
    "# def create_price_df(self,ticker, period='daily'):\n",
    "\n",
    "#     if period =='hourly':\n",
    "#         api_url = 'https://fmpcloud.io/api/v3/historical-chart/1hour'\n",
    "#     else:\n",
    "#         api_url = 'https://fmpcloud.io/api/v3/historical-price-full'\n",
    "\n",
    "#     ticker_df = json.loads(requests.get(f\"{api_url}/{ticker}?apikey={fmp_api}\").content)['historical']\n",
    "#     data = pd.DataFrame(ticker_df).set_index('date')[::-1]\n",
    "#     data['Date'] = data.index\n",
    "#     data.index = data.index.astype('datetime64[ns]')\n",
    "\n",
    "#     return data\n",
    "\n",
    "# def use_csvs(ticker):\n",
    "\n",
    "#     #data = pd.read_csv(\"../FilesExportIndividualStockDFs_Big/\"+ticker+\"_combined_df.csv\", index_col='Date', parse_dates=True)\n",
    "#     path = Path('../FilesExport_Complete_DataDicts/'+ticker+'_data_dict.pkl')\n",
    "#     data_import = load_obj(path)\n",
    "#     data = data_import['dataFrame'].copy()\n",
    "\n",
    "#     return data\n",
    "\n",
    "def get_dataframe(symbol):\n",
    "\n",
    "    #data = pd.read_csv(\"../FilesExportIndividualStockDFs_Big/\"+ticker+\"_combined_df.csv\", index_col='Date', parse_dates=True)\n",
    "    path = Path('../FilesExport_Complete_DataDicts/'+symbol+'_data_dict.pkl')\n",
    "    data_import = load_obj(path)\n",
    "    data = data_import[symbol]['dataFrame']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def bollinger_bands(dataframe,period=20):\n",
    "    data = dataframe.copy()\n",
    "    data['middle_band'] = data[['adjClose']].rolling(window=period).mean()\n",
    "    data[str(period)+'_day_stdev'] = data[['adjClose']].rolling(window=period).std()\n",
    "    data['upper_band'] = data['middle_band']+2*data[str(period)+'_day_stdev']\n",
    "    data['lower_band'] = data['middle_band'] - 2*data[str(period)+'_day_stdev']\n",
    "    data['spread'] = data['upper_band'] + data['lower_band']\n",
    "    data['change_in_spread'] = data['spread']/data['spread'].shift(1)-1\n",
    "    data[str(period)+\"_return\"] = data['adjClose']/data['adjClose'].shift(period)-1\n",
    "    data['bollinger_signal'] = data['change_in_spread'].rank(ascending=False, pct=True)\n",
    "    data.dropna()\n",
    "\n",
    "    return data\n",
    "\n",
    "def dema(dataframe, period1=10, period2=20):\n",
    "    data = dataframe.copy()\n",
    "    data[str(period1)+'ema1'] = dataframe[['adjClose']].ewm(span=period1, adjust=False).mean()\n",
    "    data[str(period1)+'ema2'] = data[str(period1)+'ema1'].ewm(span=period1, adjust=False).mean()\n",
    "    data[str(period1)+'dema'] = 2*data[str(period1)+'ema1'] - data[str(period1)+'ema2']\n",
    "    data[str(period2)+'ema1'] = data[['adjClose']].ewm(span=period2, adjust=False).mean()\n",
    "    data[str(period2)+'ema2'] = data[str(period2)+'ema1'].ewm(span=period2, adjust=False).mean()\n",
    "    data[str(period2)+'dema'] = 2*data[str(period2)+'ema1'] - data[str(period2)+'ema2']\n",
    "    data[str(period1)+\"_return\"] = data['adjClose']/data['adjClose'].shift(period1)-1\n",
    "    data['spread'] = data[str(period1)+'dema'] - data[str(period2)+'dema']\n",
    "    data['dema_signal'] = data['spread'].rank(ascending=True, pct=True)\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "def price_momentum(dataframe, smoothing1=0.0571, smoothing2=0.1, periods1=15, periods2=10):\n",
    "    data = dataframe.copy()\n",
    "    data['smoothing_factor'] = smoothing1\n",
    "    data[str(periods1)+\"average\"] = data['changeOverTime'].rolling(window=periods1).mean()\n",
    "    smoothing_factor_list = [data.iloc[periods1][str(periods1)+\"average\"]]\n",
    "    data = data.dropna()\n",
    "    i=1\n",
    "    j=0\n",
    "    while i < len(data[str(periods1)+\"average\"]):\n",
    "        smoothing_factor = data.iloc[i]['changeOverTime']*data.iloc[i]['smoothing_factor'] + smoothing_factor_list[j]*(1-data.iloc[i]['smoothing_factor'])\n",
    "        smoothing_factor_list.append(smoothing_factor)\n",
    "        j+=1\n",
    "        i+=1\n",
    "    data['35d_custom_smoothing'] = smoothing_factor_list\n",
    "    data['35d_custom_10'] = data['35d_custom_smoothing']*10\n",
    "    data['smoothing_factor2'] = smoothing2\n",
    "    data[str(periods2)+\"average\"] = data['35d_custom_10'].rolling(window=periods2).mean()\n",
    "    data = data.dropna()\n",
    "    smoothing_factor_list2 = [data.iloc[0][str(periods2)+\"average\"]]\n",
    "    i=1\n",
    "    j=0\n",
    "    while i < len(data[str(periods2)+\"average\"]):\n",
    "        smoothing_factor = (data.iloc[i]['35d_custom_10'] - smoothing_factor_list2[j])*data.iloc[i]['smoothing_factor2'] + smoothing_factor_list2[j]\n",
    "        smoothing_factor_list2.append(smoothing_factor)\n",
    "        j+=1\n",
    "        i+=1\n",
    "    data[str(periods2)+'d_custom_smoothing'] = smoothing_factor_list2\n",
    "    data[str(periods2)+\"_return\"] = data['adjClose']/data['adjClose'].shift(periods2)-1\n",
    "#         data['signal'] = np.where(data[str(periods2)+'d_custom_smoothing'] > data[str(periods2)+'d_custom_smoothing'].shift(1), 1.0, 0.0)\n",
    "#         data = data.rename(columns={'signal':'price_mo'})\n",
    "    return data\n",
    "\n",
    "def get_ichimoku_cloud(dataframe, period1=4, period2=8, period3=15):\n",
    "\n",
    "    #TODO generate signal, ichimoku works better in current market regime with shorter periods, being able to respond faster to events than a traditional version\n",
    "    # The conversion crossing the base would be the signal\n",
    "\n",
    "    data = dataframe.copy()\n",
    "    data['conversion_line'] = data[['adjClose']].rolling(window=period1).mean()\n",
    "    data['base_line'] = data[['adjClose']].rolling(window=period2).mean()\n",
    "    data['senkou_spanA_line'] = (data['conversion_line']+data['base_line'])/2\n",
    "    data['senkou_spanB_line'] = data[['adjClose']].rolling(window=period3).mean()\n",
    "    data['lagging_span'] = data['adjClose'].shift(period2)\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data\n",
    "\n",
    "def accumulation_distribution_line(dataframe):\n",
    "\n",
    "    ##TODO define periodicity and pass as arguments, use the mean as the signal generator, -1 is buy and and 1 is sell\n",
    "    ##TODO need to add ability to ignore a -1 during a range of 1s\n",
    "\n",
    "    data = dataframe.copy()\n",
    "    data['money_flow_mult'] = round(((data['adjClose'] - data['low']) - (data['high'] - data['adjClose']))/(data['high'] - data['low']),2)\n",
    "    data = data.dropna()\n",
    "    data['money_flow_volume'] = data['money_flow_mult']*data['volume']\n",
    "    money_flow_multiplier_list = list(data['money_flow_volume'].values)\n",
    "    adl = [money_flow_multiplier_list[0]]\n",
    "    i = 1\n",
    "    while i < len(money_flow_multiplier_list):\n",
    "        a_d_indicator = adl[i-1]+money_flow_multiplier_list[i]\n",
    "        adl.append(a_d_indicator)\n",
    "        i+=1\n",
    "    data['adl'] = adl\n",
    "    data['adl_change'] = data['adl']/data['adl'].shift(1)-1\n",
    "    negative_change_count = [0]*9\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    while i < len(data)-9:\n",
    "        j=0\n",
    "        while j < 9:\n",
    "            if data.iloc[j+i]['adl_change'] <0:\n",
    "                counter+=1\n",
    "            if j %19 == 0:\n",
    "                negative_change_count.append(counter)\n",
    "                counter = 0\n",
    "            j+=1\n",
    "        i+=1\n",
    "    data['negative_change_counter'] = negative_change_count\n",
    "    data['9_day_return'] = data['adjClose']/data['adjClose'].shift(9)-1\n",
    "    data['adl_signal'] = rolling_spearman(data['adl'], data['9_day_return'], 9)\n",
    "\n",
    "    return data\n",
    "\n",
    "def rsi(dataframe, periods=14):\n",
    "    data = dataframe.copy()\n",
    "    data['gains'] = np.where(data['changeOverTime']>0, data['changeOverTime'], 0)\n",
    "    data['losses'] = np.where(data['changeOverTime']<0, np.absolute(data['changeOverTime']), 0)\n",
    "    data['average_gain'] = data['gains'].rolling(window=periods).mean()\n",
    "    data['average_loss'] = data['losses'].rolling(window=periods).mean()\n",
    "    data['rs'] = data['average_gain']/data['average_loss']\n",
    "    data['rsi'] = (100 - 100/(1+data['rs']))\n",
    "    data['rsi_signal'] = data['rsi'].rank(ascending=True, pct=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# def get_ratings(self):\n",
    "\n",
    "#     ratings = json.loads(requests.get(f\"https://fmpcloud.io/api/v3/historical-rating/{self.ticker}?limit=100&apikey={fmp_api}\").content)\n",
    "#     ratings_df = pd.DataFrame(ratings)\n",
    "#     ratings_df['average_rating'] = (ratings_df['ratingScore']+ratings_df['ratingDetailsDCFScore']+ratings_df['ratingDetailsROEScore']+ratings_df['ratingDetailsROAScore'] \\\n",
    "#                                     +ratings_df['ratingDetailsDEScore'] + ratings_df['ratingDetailsPEScore']+ ratings_df['ratingDetailsPBScore'])/7\n",
    "\n",
    "#     return ratings_df\n",
    "\n",
    "# def get_stock_market_performances(self, dataframe):\n",
    "#     limit = len(dataframe)\n",
    "#     data = json.loads(requests.get(f\"https://fmpcloud.io/api/v3/historical-sectors-performance?limit=525&apikey={fmp_api}\").content)\n",
    "#     sector_df = pd.DataFrame(data).set_index('date')\n",
    "#     sector_df_clean = sector_df[::-1]\n",
    "#     s_p500 = json.loads(requests.get(f\"https://fmpcloud.io/api/v3/historical-price-full/^SP500TR?from=\"+sector_df_clean.index[0]+\"&to=\"+sector_df_clean.index[-1]+\"&apikey=\"+fmp_api).content)['historical']\n",
    "#     sp_df = pd.DataFrame(s_p500)\n",
    "#     sp_df_clean = sp_df[::-1]\n",
    "\n",
    "#     return sp_df_clean\n",
    "\n",
    "def get_all_indicators(symbol):\n",
    "    dataframe = get_dataframe(symbol)\n",
    "    bb = bollinger_bands(dataframe)\n",
    "    DEMA = dema(dataframe)\n",
    "    ADL = accumulation_distribution_line(dataframe)\n",
    "    RSI = rsi(dataframe)\n",
    "\n",
    "    dataframe['bollinger_signal'] = bb['bollinger_signal']\n",
    "    dataframe['dema_signal'] = DEMA['dema_signal']\n",
    "    dataframe['adl_signal'] = ADL['adl_signal']\n",
    "    dataframe['rsi_signal'] = RSI['rsi_signal']\n",
    "    return dataframe\n",
    "\n",
    "# def merge_data(self):\n",
    "#     ticker_list = self.stock_list\n",
    "#     for stock in ticker_list:\n",
    "#         stock_csv = self.use_csvs(stock)\n",
    "#         stock_csv['Date'] = stock_csv.index.astype(\"string\")\n",
    "#         stock_csv = stock_csv.iloc[:-1]\n",
    "#         stock_csv.index.names =[\"\"]\n",
    "#         stock_indicators = self.get_all_indicators(stock)\n",
    "#         stock_signals = stock_indicators[['Date','bollinger_signal','dema_signal', 'adl_signal', 'rsi_signal']]\n",
    "#         stock_signals.loc[:,'Date'] = stock_signals['Date'].astype('string')\n",
    "#         stock_signals.index.names =[\"\"]\n",
    "#         merged_data = pd.merge(left = stock_csv, right=stock_signals, on=['Date']).set_index('Date')\n",
    "#         merged_data = merged_data.dropna()\n",
    "#         writer = pd.ExcelWriter(\"NewCsvs/\"+stock+\"_all_indicator_dfs.xlsx\", engine=\"xlsxwriter\")\n",
    "\n",
    "#         merged_data.to_excel(writer, sheet_name=stock+\"_data\")\n",
    "\n",
    "#         writer.save()\n",
    "\n",
    "#     return print(\"All files successfully saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7cbd06a-a6bd-4af0-9475-84d3483d7de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1563"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import symbol list \n",
    "import_path = '../Resources/05_machine_learning_dict.pkl'\n",
    "machine_learning_dict = load_obj(import_path)\n",
    "len(machine_learning_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198b2730-d806-4093-8d23-fcfd7135d152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\watso\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:135: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_success_list = []\n",
    "for symbol in machine_learning_dict:\n",
    "    temp_dict = {}\n",
    "    try:\n",
    "        df = get_all_indicators(symbol)\n",
    "    except: continue \n",
    "        \n",
    "    df = df.dropna()\n",
    "    \n",
    "    if len(df) > 1400:\n",
    "        temp_dict[symbol] = df\n",
    "        #data_dict[symbol] = df \n",
    "        symbol_success_list.append(symbol)\n",
    "        \n",
    "        ## Export Temp dict \n",
    "        export_path = Path('../FilesExport_Complete_DFs_TI_noShift/'+symbol+'_TI_DF_no_shift.pkl')\n",
    "        save_obj(temp_dict,export_path)\n",
    "        \n",
    "        \n",
    "len(symbol_success_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8b9100-8fea-45a3-b18b-8ee2d7307199",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export symbol_success_list as ML_symbol_success_list.pkl\n",
    "export_path = Path('../Resources/06_01_ML_symbol_success_list.pkl')\n",
    "save_obj(symbol_success_list,export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926e989-b3fe-45c3-8d0a-3b18eb0e7036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
