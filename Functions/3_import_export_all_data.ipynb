{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e07fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a1a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set start date variable - dataframes will be created starting from this date\n",
    "start_date = '2020-09-14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa2fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calls and Functions for reading data downloaded from SEC website \n",
    "header = \"SETTLEMENT DATE|CUSIP|SYMBOL|QUANTITY (FAILS)|DESCRIPTION|PRICE\"\n",
    "\n",
    "path = r'C:/Users/watso/Desktop/FTDProject/SEC_Files_CSV' # USE YOUR PATH \n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "GME_CUSIP_number = \"36467W109\"   \n",
    "GME_symbol = 'GME'\n",
    "\n",
    "# CUSIP_number = \"36467W109\"   # Default  \n",
    "# symbol = 'GME'               # Default\n",
    "\n",
    "# Main function - passing the CUSIP number (most important) and setting the symbol will deliver\n",
    "#                 FTD data sorted by CUSIP number \n",
    "# All other functions here exist to support this \n",
    "def return_dataframe(cusip_number,symbol):\n",
    "    df = read_ftd_data_any_stock(cusip_number,symbol)\n",
    "    df = fix_dataframe(df)\n",
    "    return df\n",
    "\n",
    "# Use return_dataframe as your function to call FTD Data \n",
    "\n",
    "\n",
    "# Imports and reads original SEC data , finds and returns dataframe of each CSV file \n",
    "def read_ftd_file(csv_path, cusip_number, symbol):\n",
    "    data = pd.read_csv(\n",
    "    Path(csv_path),\n",
    "    index_col=False\n",
    "    )\n",
    "    \n",
    "    data[header] = data[header].str.replace('|',',')\n",
    "    new_data = data.rename(columns={header:'SETTLEMENT_DATE,CUSIP,SYMBOL,QUANTITY_FAILS,DESCRIPTION,PRICE'})\n",
    "    Header = \"Header\"\n",
    "    new_data = data.rename(columns={header:Header})\n",
    "    \n",
    "    new_data = new_data.Header.str.split(\",\",expand=True)\n",
    "    new_data = new_data.rename(columns={0:'Date',1:'CUSIP',2:'SYMBOL',3:'QUANTITY_FAILS',4:'DESCRIPTION',5:'PRICE'})\n",
    "    \n",
    "    new_data = new_data.set_index(\"CUSIP\")\n",
    "    new_data = new_data.loc[cusip_number]\n",
    "    \n",
    "    new_data = new_data[['Date','QUANTITY_FAILS','PRICE']]\n",
    "    new_data.rename(columns={'PRICE':symbol},inplace=True)\n",
    "    new_data.set_index('Date',inplace=True)  \n",
    "    \n",
    "    new_data = new_data.reset_index()\n",
    "    new_data['Date'] = pd.to_datetime(new_data['Date'])\n",
    "    new_data.set_index('Date',inplace=True)\n",
    "    new_data = new_data[['QUANTITY_FAILS']]\n",
    "    new_data.rename(columns={'QUANTITY_FAILS':symbol+'_QUANTITY_FAILS'},inplace=True)\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "\n",
    "def fix_dataframe(dataframe):\n",
    "    # For whatever reason, exporting data to CSV file, then reimporting back in using Pandas\n",
    "    # solves all issues when it comes to reading the data in the column \n",
    "    dataframe.to_csv('../FilesTemp/temp.csv')\n",
    "    dataframe = pd.read_csv(\n",
    "        Path('../FilesTemp/temp.csv'),\n",
    "        infer_datetime_format=True,\n",
    "        parse_dates=True,\n",
    "        index_col=\"Date\",\n",
    "    )\n",
    "    dataframe.sort_index(inplace=True)\n",
    "    dataframe.drop_duplicates(inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "# Concat function to join DataFrames \n",
    "def concat_df(df_1,df_2):\n",
    "    df = pd.concat([df_1,df_2],axis='rows')\n",
    "    return df\n",
    "\n",
    "\n",
    "# This function can be used to call data from the SEC files using any CUSIP number\n",
    "def read_ftd_data_any_stock(cusip_number,symbol):\n",
    "    new_df = pd.DataFrame()\n",
    "    for filename in all_files:\n",
    "        if filename == 0:\n",
    "            new_df = read_ftd_file(csv_path=filename ,cusip_number=cusip_number,symbol=symbol)\n",
    "        else:\n",
    "            new_df2 = read_ftd_file(csv_path=filename ,cusip_number=cusip_number,symbol=symbol)\n",
    "            new_df = concat_df(new_df,new_df2)\n",
    "            \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0efb8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IEX Setup and Test \n",
    "\n",
    "# Don't seem to need to use real API Key \n",
    "# Sandbox API key works just fine for data \n",
    "\n",
    "#iex_api_key = os.getenv(\"IEX_API_KEY\")\n",
    "iex_test_api_key = os.getenv(\"IEX_TEST_API_KEY\")\n",
    "\n",
    "base_url = 'https://cloud.iexapis.com/stable/'\n",
    "sandbox_url = 'https://sandbox.iexapis.com/stable/'\n",
    "\n",
    "#token = os.environ.get('IEX_API_KEY')\n",
    "test_token = os.environ.get('IEX_TEST_API_KEY')\n",
    "\n",
    "test_resp = requests.get(base_url + 'status')\n",
    "test_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad91854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IEX Calls and Functions \n",
    "\n",
    "def get_chart(stock_ticker, chart_range='14m'):\n",
    "    resp_data = requests.get(sandbox_url+'stock/'+stock_ticker+'/chart/'+chart_range+'?token='+test_token)\n",
    "    df = pd.DataFrame(resp_data.json())\n",
    "\n",
    "    df.rename(columns={'date':'Date'},inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date',inplace=True)\n",
    "    \n",
    "    return df \n",
    "\n",
    "def get_close_price(stock_ticker, chart_range='14m'):\n",
    "\n",
    "    resp_data = requests.get(sandbox_url+'stock/'+stock_ticker+'/chart/'+chart_range+'?token='+test_token)\n",
    "    df = pd.DataFrame(resp_data.json())\n",
    "\n",
    "    df.rename(columns={'date':'Date'},inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date',inplace=True)\n",
    "    \n",
    "    df = df[['close']]\n",
    "    #df.rename(columns={'close':stock_ticker},inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_daily_data(stock_ticker, chart_range='14m'):\n",
    "\n",
    "    resp_data = requests.get(sandbox_url+'stock/'+stock_ticker+'/chart/'+chart_range+'?token='+test_token)\n",
    "    df = pd.DataFrame(resp_data.json())\n",
    "\n",
    "    df.rename(columns={'date':'Date'},inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date',inplace=True)\n",
    "    \n",
    "    df = df[['close','open','low','high','volume']]\n",
    "    #df.rename(columns={'close':stock_ticker},inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def join_ftd_and_close(ftd_df,close_df):\n",
    "    merged_df = ftd_df.merge(close_df, how='inner',right_index=True, left_index=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88dcc346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_all(cusip_number,symbol,chart_range='14m'):\n",
    "    # Default chart_range value = '1y' \n",
    "    # Get FTD Data\n",
    "    ftd_df = return_dataframe(cusip_number,symbol)\n",
    "    # Get Close Data \n",
    "    close_df = get_close_price(symbol,chart_range)\n",
    "    # Merge Data together \n",
    "    merged_df = join_ftd_and_close(ftd_df,close_df)\n",
    "    return merged_df\n",
    "\n",
    "def do_more(cusip_number,symbol,chart_range='14m'):\n",
    "    # Default chart_range value = '1y' \n",
    "    # Get FTD Data\n",
    "    ftd_df = return_dataframe(cusip_number,symbol)\n",
    "    # Get Close Data \n",
    "    close_df = get_daily_data(symbol,chart_range)\n",
    "    # Merge Data together \n",
    "    merged_df = join_ftd_and_close(ftd_df,close_df)\n",
    "    return merged_df\n",
    "\n",
    "def do_all_and_export(cusip_number,symbol,chart_range='14m'):\n",
    "    # Default chart_range value = '1y' \n",
    "    # Get FTD Data\n",
    "    ftd_df = return_dataframe(cusip_number,symbol)\n",
    "    # Get Close Data \n",
    "    close_df = get_daily_data(symbol,chart_range)\n",
    "    # Merge Data together \n",
    "    merged_df = join_ftd_and_close(ftd_df,close_df)\n",
    "    # Export Data \n",
    "    merged_df.to_csv('../FilesExport/'+symbol+'_all_data.csv')\n",
    "    return merged_df\n",
    "\n",
    "def export_ftd_csv_data(dataframe,symbol):    \n",
    "    dataframe.to_csv('../FilesExport/'+symbol+'_ftd_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c236e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_info(symbol):\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    ticker_info = ticker.info\n",
    "    sharesOutstanding = ticker_info['sharesOutstanding']\n",
    "    floatShares = ticker_info['floatShares']\n",
    "    dictionary = {\n",
    "        'SharesOutstanding' : sharesOutstanding,\n",
    "        'FloatShares' : floatShares\n",
    "    }\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1779113",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read FTD files to make list of tickers to get data  \n",
    "## Load three FTD files to increase the amount of stock tickers to parse \n",
    "data = pd.read_csv(\n",
    "    Path(\"../SEC_Files_CSV/sec_ftd_202109a.csv\"),\n",
    "    index_col=False\n",
    ")\n",
    "dat2 = pd.read_csv(\n",
    "    Path(\"../SEC_Files_CSV/sec_ftd_202108b.csv\"),\n",
    "    index_col=False\n",
    ")\n",
    "dat3 = pd.read_csv(\n",
    "    Path(\"../Resources/sec_ftd_1.csv\"),  ## Original File parsed for original test of Code. \n",
    "    index_col=False                      ## Including it to make sure no tickers are missed \n",
    ")                                        ## relative to previous tests reading this data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eba8666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\watso\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  \n",
      "C:\\Users\\watso\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\watso\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n"
     ]
    }
   ],
   "source": [
    "header = \"SETTLEMENT DATE|CUSIP|SYMBOL|QUANTITY (FAILS)|DESCRIPTION|PRICE\"\n",
    "data[header] = data[header].str.replace('|',',')\n",
    "new_data = data.rename(columns={header:'SETTLEMENT_DATE,CUSIP,SYMBOL,QUANTITY_FAILS,DESCRIPTION,PRICE'})\n",
    "Header = \"Header\"\n",
    "new_data = data.rename(columns={header:Header})\n",
    "new_df = pd.DataFrame()\n",
    "new_df = new_data.Header.str.split(\",\",expand=True)\n",
    "new_df = new_df.rename(columns={0:'Date',1:'CUSIP',2:'SYMBOL',3:'QUANTITY_FAILS',4:'DESCRIPTION',5:'PRICE'})\n",
    "\n",
    "dat2[header] = dat2[header].str.replace('|',',')\n",
    "new_dat2 = dat2.rename(columns={header:'SETTLEMENT_DATE,CUSIP,SYMBOL,QUANTITY_FAILS,DESCRIPTION,PRICE'})\n",
    "Header = \"Header\"\n",
    "new_dat2 = dat2.rename(columns={header:Header})\n",
    "new_d2 = pd.DataFrame()\n",
    "new_d2 = new_dat2.Header.str.split(\",\",expand=True)\n",
    "new_d2 = new_d2.rename(columns={0:'Date',1:'CUSIP',2:'SYMBOL',3:'QUANTITY_FAILS',4:'DESCRIPTION',5:'PRICE'})\n",
    "\n",
    "dat3[header] = dat3[header].str.replace('|',',')\n",
    "new_dat3 = dat3.rename(columns={header:'SETTLEMENT_DATE,CUSIP,SYMBOL,QUANTITY_FAILS,DESCRIPTION,PRICE'})\n",
    "Header = \"Header\"\n",
    "new_dat3 = dat3.rename(columns={header:Header})\n",
    "new_d3 = pd.DataFrame()\n",
    "new_d3 = new_dat3.Header.str.split(\",\",expand=True)\n",
    "new_d3 = new_d3.rename(columns={0:'Date',1:'CUSIP',2:'SYMBOL',3:'QUANTITY_FAILS',4:'DESCRIPTION',5:'PRICE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ba861f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>SYMBOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B38564108</td>\n",
       "      <td>EURN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D18190898</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G00748106</td>\n",
       "      <td>STWO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G00748114</td>\n",
       "      <td>STWOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G0083D104</td>\n",
       "      <td>ACEVW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13656</th>\n",
       "      <td>98475Y105</td>\n",
       "      <td>YRIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13657</th>\n",
       "      <td>986008100</td>\n",
       "      <td>YOKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13658</th>\n",
       "      <td>98880P202</td>\n",
       "      <td>ZZLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13659</th>\n",
       "      <td>989424205</td>\n",
       "      <td>ZENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13660</th>\n",
       "      <td>98979N100</td>\n",
       "      <td>ZTLLF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13661 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CUSIP SYMBOL\n",
       "0      B38564108   EURN\n",
       "1      D18190898     DB\n",
       "2      G00748106   STWO\n",
       "3      G00748114  STWOW\n",
       "4      G0083D104  ACEVW\n",
       "...          ...    ...\n",
       "13656  98475Y105   YRIV\n",
       "13657  986008100  YOKEY\n",
       "13658  98880P202   ZZLL\n",
       "13659  989424205   ZENO\n",
       "13660  98979N100  ZTLLF\n",
       "\n",
       "[13661 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cusip_df1 = new_df[['CUSIP','SYMBOL']]\n",
    "cusip_df2 = new_d2[['CUSIP','SYMBOL']]\n",
    "cusip_df3 = new_d3[['CUSIP','SYMBOL']]\n",
    "cusip_df = concat_df(cusip_df1,cusip_df2)\n",
    "cusip_df.drop_duplicates(inplace=True)\n",
    "cusip_df.reset_index(inplace=True)\n",
    "cusip_df.drop(columns='index',inplace=True)\n",
    "cusip_df = concat_df(cusip_df,cusip_df3)\n",
    "cusip_df.drop_duplicates(inplace=True)\n",
    "cusip_df.reset_index(inplace=True)\n",
    "cusip_df.drop(columns='index',inplace=True)\n",
    "cusip_df.set_index('CUSIP',inplace=True)\n",
    "cusip_df.dropna(inplace=True)\n",
    "cusip_df.reset_index(inplace=True)\n",
    "cusip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "050aa34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cusip_df.to_csv('../Resources/cusip_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24f4f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IEX Call function for sharesOutstanding \n",
    "## IEX Does not call Float data :\n",
    "## returns a '0' for any stock since Dec 2020 \n",
    "# GET /stock/{symbol}/stats/{stat?}\n",
    "\n",
    "def get_outstanding_shares(stock_ticker):\n",
    "    response = requests.get(sandbox_url+'stock/'+stock_ticker+'/stats/sharesOutstanding?token='+test_token)\n",
    "    try:\n",
    "        variable = response.json()\n",
    "    except json.decoder.JSONDecodeError:     ## Exception to mark stock tickers that fail IEX call \n",
    "            variable = 0.01\n",
    "    \n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9461ef0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13662"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_variable = 1.0\n",
    "length_of_df = len(cusip_df)\n",
    "\n",
    "length_of_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9118744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_list_return(data_list, range_obj, title):\n",
    "    dfObj = pd.DataFrame(columns=['CUSIP', 'SYMBOL', 'YTD_FTD_SUM','sharesOutstanding','YTD_PCT_OUTSTANDING'])\n",
    "\n",
    "    for i in range_obj:\n",
    "        cusip = data_list['CUSIP'][i]        \n",
    "        symbol = data_list['SYMBOL'][i]\n",
    "\n",
    "        try:\n",
    "            temp_df = return_dataframe(cusip,symbol)\n",
    "            temp_sum = temp_df.sum() \n",
    "            ticker_info = get_outstanding_shares(symbol)\n",
    "            ytd_pct = temp_sum[0] / ticker_info * 100\n",
    "            if ytd_pct >= pct_variable:\n",
    "                dfObj = dfObj.append(\n",
    "                    {'CUSIP': cusip, \n",
    "                     'SYMBOL': symbol,\n",
    "                     'YTD_FTD_SUM': temp_sum[0],\n",
    "                     'sharesOutstanding': ticker_info,\n",
    "                     'YTD_PCT_OUTSTANDING' : ytd_pct}, \n",
    "                    ignore_index=True)            \n",
    "        except KeyError: \n",
    "            continue\n",
    "        except TypeError:\n",
    "            continue\n",
    "        \n",
    "\n",
    "    dfObj.to_csv('../FilesExportFTD/'+title+'_df.csv')\n",
    "    return dfObj\n",
    "\n",
    "def iterate_list_export(data_list, range_obj, title):\n",
    "    dfObj = pd.DataFrame(columns=['CUSIP', 'SYMBOL', 'YTD_FTD_SUM','sharesOutstanding','YTD_PCT_OUTSTANDING'])\n",
    "\n",
    "    for i in range_obj:\n",
    "        cusip = data_list['CUSIP'][i]        \n",
    "        symbol = data_list['SYMBOL'][i]\n",
    "\n",
    "        try:\n",
    "            temp_df = return_dataframe(cusip,symbol)   # Parses all the SEC File Data \n",
    "            temp_sum = temp_df.sum()                   # Sums all the FTD File data \n",
    "            ticker_info = get_outstanding_shares(symbol)  # Acccess API, get the OutstandingShares \n",
    "            ytd_pct = temp_sum[0] / ticker_info * 100     # Calculate the Percent \n",
    "            if ytd_pct >= pct_variable:                   # Sort data great than 1% (pct_variable) \n",
    "                dfObj = dfObj.append(\n",
    "                    {'CUSIP': cusip, \n",
    "                     'SYMBOL': symbol,\n",
    "                     'YTD_FTD_SUM': temp_sum[0],\n",
    "                     'sharesOutstanding': ticker_info,\n",
    "                     'YTD_PCT_OUTSTANDING' : ytd_pct},    # Append data to list and its relevant columns \n",
    "                    ignore_index=True)            \n",
    "        except KeyError:                          \n",
    "            continue\n",
    "        except TypeError:               # (no more than 1 day of FTD posted in a two week period)\n",
    "            continue                    # issue with return_dataframe() and accessing a single entry in the SEC file data\n",
    "        \n",
    "\n",
    "    dfObj.to_csv('../FilesExportFTD/'+title+'_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d880010",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test with range of 100 to make sure functions work \n",
    "# range_1 = range(0,100)\n",
    "# range_test = iterate_list_return(cusip_df,range_1,'range_1_test')\n",
    "# range_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3cba4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\watso\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n"
     ]
    }
   ],
   "source": [
    "## Use while loop to iterate through data and create CSV files to be read\n",
    "## If data fails at any point, can locate roughly where it failed by reading \n",
    "## titles of exported files, and can fix the problem and continue from where it left off  \n",
    "\n",
    "## Skipped 11700 , 11800\n",
    "\n",
    "x = 11800\n",
    "y = 11900\n",
    "\n",
    "while x <= (length_of_df-200):\n",
    "    range_var = range(x,y)    \n",
    "    str_symbol1 = str(y)\n",
    "    str_symbol2 = str(x)\n",
    "    \n",
    "    iterate_list_export(cusip_df,range_var,'range_'+str_symbol1+'_'+str_symbol2)\n",
    "    x += 100\n",
    "    y += 100\n",
    "    #symbol += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43792a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\watso\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n"
     ]
    }
   ],
   "source": [
    "## Parses the final values of the list of CUSIPs and Symbols \n",
    "## Setup this way to avoid issues with length of DF in previous while loop\n",
    "last_range = (length_of_df-200)\n",
    "range_var = range(last_range,length_of_df)    \n",
    "str_symbol1 = str(length_of_df)\n",
    "str_symbol2 = str(last_range)\n",
    "\n",
    "iterate_list_export(cusip_df,range_var,'range_'+str_symbol1+'_'+str_symbol2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ab39753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fix missed data \n",
    "## Skipped 11700 , 11800\n",
    "## Problem is with the cusip value 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dd7e7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\watso\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>YTD_FTD_SUM</th>\n",
       "      <th>sharesOutstanding</th>\n",
       "      <th>YTD_PCT_OUTSTANDING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CUSIP, SYMBOL, YTD_FTD_SUM, sharesOutstanding, YTD_PCT_OUTSTANDING]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_1 = range(11700,11800)\n",
    "range_test = iterate_list_return(cusip_df,range_1,'range_11800_11700')\n",
    "range_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0baa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
