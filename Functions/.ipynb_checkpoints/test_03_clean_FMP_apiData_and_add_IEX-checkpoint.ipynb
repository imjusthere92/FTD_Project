{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32adf7b2-a366-4abf-868b-7499a32a017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FMP is being currently used to source historical price data - it is exporting historical data to individual CSV files for each symbol \n",
    "## In theory - should be possible to parse the CSV files for historical data, and append missing data from FMP via IEX and make more \n",
    "## complete data frames. FMP has an issue where it can't source fundamentals data (market cap, outstandingshares) for ETFs. IEX can. \n",
    "## Need to come up with code to fill in the gaps from FMP with IEX data. Unlike FMP, IEX has limited API calls, so should attempt to \n",
    "## source FMP first and then call IEX to fill in gaps \n",
    "\n",
    "## Rewrite of code to be more clean, no test code, and to work more on applying more fields of data to \"Fundamentals field\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad2a386-4587-453c-8440-ea177ed5bc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#import quandl\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f3b6fb-a23d-4e75-a61a-578e338c13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants \n",
    "\n",
    "## Set start date variable - dataframes will be created starting from this date\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2021-10-29'\n",
    "default_date_range = '2y' ## Default Range for IEX functions - don't need more at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573e2fe7-5523-412d-9d76-ab061a7d52db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IEX Constants\n",
    "iex_api_key = os.getenv(\"IEX_API_KEY\")\n",
    "iex_test_api_key = os.getenv(\"IEX_TEST_API_KEY\")\n",
    "\n",
    "## Redundant Assignment but improves Readability throughout code \n",
    "real_token = iex_api_key\n",
    "test_token = iex_test_api_key\n",
    "\n",
    "base_url_iex = 'https://cloud.iexapis.com/stable/'\n",
    "sandbox_url = 'https://sandbox.iexapis.com/stable/'\n",
    "\n",
    "## IEX Status Test \n",
    "test_resp = requests.get(base_url_iex + 'status')\n",
    "test_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "140af762-d7d9-45d9-ab72-1bebaac0193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_status = test_token ## Set to either real token or test token for IEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a6cc5c0-ab7a-449e-b8e4-3cae553ddd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load IEX to get ETF statistics \n",
    "def get_IEX_statistics(stock_ticker, token=token_status):\n",
    "    if token == test_token:\n",
    "        resp_data = requests.get(sandbox_url+'stock/'+stock_ticker+'/stats/?token='+test_token)\n",
    "        data_json = resp_data.json()\n",
    "    elif token == real_token:\n",
    "        resp_data = requests.get(base_url_iex+'stock/'+stock_ticker+'/stats/?token='+real_token)\n",
    "        data_json = resp_data.json()\n",
    "        \n",
    "    return data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1a6cdb4-cd8c-4eef-90e4-fc4a064fa249",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FMP Constants \n",
    "fmpbase_urlv3 = 'https://fmpcloud.io/api/v3/'\n",
    "fmpbase_urlv4 = 'https://fmpcloud.io/api/v4/'\n",
    "api_key = os.getenv(\"FMP_CLOUD_API_KEY\")\n",
    "\n",
    "## FMP Functions - this file should not need to call the historical data function. \n",
    "##                 This file should import the CSV files with historical data and then append IEX testing data\n",
    "##                 to any data FMP cannot source. \n",
    "def get_FMP_historical_data(symbol, startDate=start_date, endDate=end_date, apiKey=api_key):\n",
    "    url_hist_price = fmpbase_urlv3+'historical-price-full/'\n",
    "    url_hist_query_with_date = url_hist_price+symbol+'?from='+startDate+'&to='+endDate+'&apikey='+apiKey\n",
    "    resp_data = requests.get(url_hist_query_with_date)\n",
    "    json_ = resp_data.json()\n",
    "    data = json_['historical']\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={'date':'Date'},inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.reindex(index=df.index[::-1]) ## Reverse the DataFrame \n",
    "    df.set_index('Date',inplace=True)\n",
    "    df.drop(columns='label',inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_float_data_FMP(symbol):\n",
    "    url_float_shares = fmpbase_urlv4+'shares_float?symbol='\n",
    "    url_query_float_data = url_float_shares+symbol+'&apikey='+api_key\n",
    "    resp_data = requests.get(url_query_float_data)\n",
    "    #df = pd.DataFrame(resp_data.json())\n",
    "    json_ = resp_data.json()\n",
    "    return json_[0]\n",
    "\n",
    "def get_company_profile_FMP_json(symbol):\n",
    "    ## https://fmpcloud.io/api/v3/profile/AAPL?apikey='yourkeyhere'\n",
    "    url_company_profile_url = fmpbase_urlv3+'profile/'+symbol+'?apikey='+api_key\n",
    "    resp_data = requests.get(url_company_profile_url)\n",
    "    json_response = resp_data.json()\n",
    "    return json_response[0]\n",
    "\n",
    "# def save_and_export_raw_df_csv(data, symbol):\n",
    "#     path = ('../FilesExportIndividualStockDFs/'+symbol+'_combined_df.csv')\n",
    "#     data.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a035b741-2878-4f68-8cd1-04138d7a20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use pickle module to import and export and save files\n",
    "import pickle\n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "def save_obj(obj, path ):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "073a1984-6e1b-42ee-b5f4-48387c10f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## Import FTD File using CSV \n",
    "# # ftd_df = pd.read_csv(\n",
    "# #     Path('../Resources/ftd_all_data.csv'),\n",
    "# #     index_col=0, parse_dates=True\n",
    "# # )\n",
    "\n",
    "# ## Don't need FTD file at the moment. Import symbol_df as a way to get symbols to iterate through saved CSVs. \n",
    "# ## Some symbols will fail, need to create function that skips missed indexes \n",
    "\n",
    "# ## Import Symbol and CUSIP list using CSV\n",
    "# symbol_df = pd.read_csv(\n",
    "#     Path('../Resources/symbol_all_list.csv'),\n",
    "#     index_col=0\n",
    "# )\n",
    "\n",
    "\n",
    "## Do not seem to be needed for this file, but code here anyway if either file is needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ed9c53-e2ae-4491-8988-58a7d0bb658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## How to find index value of specific stock \n",
    "# index_value = 0\n",
    "# for i in complete_key_list:\n",
    "#     if i == 'ACP':\n",
    "#         print(index_value)\n",
    "#         break\n",
    "#     index_value +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2a2d374-d6f7-41c7-bc11-a2c90b26da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "y = 49\n",
    "increment = 50\n",
    "imported_data_dict = {}\n",
    "\n",
    "test_length = 1500\n",
    "## Current last file is 8450 \n",
    "while x < test_length:\n",
    "    str_symbol1 = str(x)\n",
    "    str_symbol2 = str(y)\n",
    "    \n",
    "    pkl_path = Path('../FilesExportCompleteFMP/data_complete_'+str_symbol1+'_'+str_symbol2+'.pkl')\n",
    "    data_obj = load_obj(pkl_path)\n",
    "    data_obj_key_list = []\n",
    "    for key in data_obj.keys():\n",
    "        data_obj_key_list.append(key)  \n",
    "    for symbol in data_obj_key_list:\n",
    "        data = data_obj[symbol]\n",
    "        imported_data_dict[symbol] = data\n",
    "        \n",
    "    x += increment\n",
    "    y += increment\n",
    "    \n",
    "imported_key_list = []\n",
    "for key in imported_data_dict.keys():\n",
    "    imported_key_list.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb8ac5fc-f682-4ef2-a2f7-df90094297d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_ = len(imported_data_dict)\n",
    "length_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f82bea94-8daf-439b-a125-42de12874678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241 ARKQ\n"
     ]
    }
   ],
   "source": [
    "## Find index value of specific symbol \n",
    "index_value = 0\n",
    "for i in imported_key_list:\n",
    "    if i == 'ARKQ':\n",
    "        print(index_value,i)\n",
    "        break\n",
    "    index_value +=1\n",
    "    if index_value == length_: print(\"No\")\n",
    "\n",
    "#complete_data_dict['ARKQ']\n",
    "\n",
    "## Trying to use ARKQ as a 'control' ETF. Any info applied to it should also apply to other valid ETFs for data gathering\n",
    "## Capping list at 250 because don't need all symbols \n",
    "## See test_length variable above as well to extend data collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85bd8a8e-ff9f-470d-88dc-31af09c332a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_symbol = 'ARKQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "015b0c9d-7c77-4bb9-93c5-109bdd66fd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imported_key_list)\n",
    "new_key_list = imported_key_list[0:250]\n",
    "len(new_key_list)\n",
    "imported_key_list = new_key_list\n",
    "len(imported_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "549b664a-6fc9-483b-a9ca-40f39f19e335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "226\n"
     ]
    }
   ],
   "source": [
    "etf_data_dict = {} \n",
    "equity_data_dict = {}\n",
    "no_profile_data_dict = {}\n",
    "error_count = 0                  ## Can use to check index in complete_key_list when loop fails \n",
    "for i in imported_key_list:\n",
    "    #symbol = i \n",
    "    if imported_data_dict[i]['companyProfile'] != 0:\n",
    "        if imported_data_dict[i]['companyProfile']['isEtf'] == True:   ## Add to etf_data_dict\n",
    "            data = imported_data_dict[i]\n",
    "            etf_data_dict[i] = data\n",
    "        else:                                   ## Add to equity_data_dict\n",
    "            data = imported_data_dict[i]\n",
    "            equity_data_dict[i] = data\n",
    "    else:                                      ## Add to no_profile_data_dict\n",
    "        data = imported_data_dict[i]\n",
    "        no_profile_data_dict[i] = data\n",
    "    error_count += 1\n",
    "    \n",
    "etf_key_list = []\n",
    "for key in etf_data_dict.keys():\n",
    "    etf_key_list.append(key)\n",
    "print(len(etf_data_dict))\n",
    "\n",
    "equity_key_list = []\n",
    "for key in equity_data_dict.keys():\n",
    "    equity_key_list.append(key)\n",
    "print(len(equity_data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05045543-4aa9-4a6e-a68a-5fe360a36e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 AAPL\n"
     ]
    }
   ],
   "source": [
    "## Shorten equity_key_list for testing \n",
    "## Find index value of specific symbol \n",
    "index_value = 0\n",
    "for i in equity_key_list:\n",
    "    if i == 'AAPL':\n",
    "        print(index_value,i)\n",
    "        break\n",
    "    index_value +=1\n",
    "    if index_value == length_: print(\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "702eaa6e-e944-4f15-8ea1-0b9d261620bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "equity_key_list = equity_key_list[0:50]\n",
    "print(len(equity_key_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8454e260-a1a3-4963-b579-dba82e00fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_status = test_token ## Set to either real token or test token for IEX\n",
    "\n",
    "# ## Loop to get ETF stats \n",
    "# for i in etf_key_list:\n",
    "#     symbol = i \n",
    "#     iex_etf_stats = get_IEX_statistics(symbol)\n",
    "#     #sharesOutstanding = iex_etf_stats['sharesOutstanding']   \n",
    "#     etf_data_dict[i]['Fundamentals']['sharesOutstanding'] = iex_etf_stats['sharesOutstanding']\n",
    "#     etf_data_dict[i]['Fundamentals']['peRatio'] = iex_etf_stats['peRatio']\n",
    "#     etf_data_dict[i]['Fundamentals']['beta'] = iex_etf_stats['beta']\n",
    "#     etf_data_dict[i]['Fundamentals']['week52high'] = iex_etf_stats['week52high']\n",
    "#     etf_data_dict[i]['Fundamentals']['week52low'] = iex_etf_stats['week52low']\n",
    "#     etf_data_dict[i]['Fundamentals']['week52change'] = iex_etf_stats['week52change']\n",
    "#     etf_data_dict[i]['Fundamentals']['avg10Volume'] = iex_etf_stats['avg10Volume']\n",
    "#     etf_data_dict[i]['Fundamentals']['avg30Volume'] = iex_etf_stats['avg30Volume']\n",
    "#     etf_data_dict[i]['Fundamentals']['marketcap_IEX'] = iex_etf_stats['marketcap']    \n",
    "    \n",
    "#     ## Replace 'marketCap' and put into 'marketcap_FMP', then delete 'marketCap' to seperate sources\n",
    "#     etf_data_dict[i]['Fundamentals']['marketcap_FMP'] = etf_data_dict[i]['Fundamentals']['marketCap']\n",
    "#     del etf_data_dict[i]['Fundamentals']['marketCap']\n",
    "#     del etf_data_dict[i]['Fundamentals']['price_earnings']\n",
    "    \n",
    "#     etf_data_dict[i]['iex_statistics'] = iex_etf_stats\n",
    "    \n",
    "# ## Loop to get Equity stats \n",
    "# for i in equity_key_list:\n",
    "#     symbol = i \n",
    "#     iex_etf_stats = get_IEX_statistics(symbol)\n",
    "#     #sharesOutstanding = iex_etf_stats['sharesOutstanding']   \n",
    "#     equity_data_dict[i]['Fundamentals']['sharesOutstanding'] = iex_etf_stats['sharesOutstanding']\n",
    "#     equity_data_dict[i]['Fundamentals']['peRatio'] = iex_etf_stats['peRatio']\n",
    "#     equity_data_dict[i]['Fundamentals']['beta'] = iex_etf_stats['beta']\n",
    "#     equity_data_dict[i]['Fundamentals']['week52high'] = iex_etf_stats['week52high']\n",
    "#     equity_data_dict[i]['Fundamentals']['week52low'] = iex_etf_stats['week52low']\n",
    "#     equity_data_dict[i]['Fundamentals']['week52change'] = iex_etf_stats['week52change']\n",
    "#     equity_data_dict[i]['Fundamentals']['avg10Volume'] = iex_etf_stats['avg10Volume']\n",
    "#     equity_data_dict[i]['Fundamentals']['avg30Volume'] = iex_etf_stats['avg30Volume']\n",
    "#     equity_data_dict[i]['Fundamentals']['marketcap_IEX'] = iex_etf_stats['marketcap']    \n",
    "    \n",
    "#     ## Replace 'marketCap' and put into 'marketcap_FMP', then delete 'marketCap' to seperate sources\n",
    "#     equity_data_dict[i]['Fundamentals']['marketcap_FMP'] = equity_data_dict[i]['Fundamentals']['marketCap']\n",
    "#     del equity_data_dict[i]['Fundamentals']['marketCap']\n",
    "#     del equity_data_dict[i]['Fundamentals']['price_earnings']\n",
    "    \n",
    "#     equity_data_dict[i]['iex_statistics'] = iex_etf_stats\n",
    "    \n",
    "\n",
    "# ## Export equity/etf data \n",
    "# pkl_path_etf = Path('../Resources/complete_etf_data_dict.pkl')\n",
    "# pkl_path_equity = Path('../Resources/complete_equity_data_dict.pkl')\n",
    "# save_obj(etf_data_dict,pkl_path_etf)\n",
    "# save_obj(equity_data_dict,pkl_path_equity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfed2697-a582-4911-ad7a-883a9356706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try doing in one loop \n",
    "full_key_list = []\n",
    "full_key_data_dict = {}\n",
    "notfull_key_list = []\n",
    "notfull_key_data_dict = {}\n",
    "for i in imported_key_list:\n",
    "    if imported_data_dict[i]['companyProfile'] != 0:\n",
    "        full_key_list.append(i)\n",
    "        data = imported_data_dict[i]\n",
    "        full_key_data_dict[i] = data\n",
    "    elif imported_data_dict[i]['companyProfile'] == 0:\n",
    "        notfull_key_list.append(i)\n",
    "        data = imported_data_dict[i]\n",
    "        notfull_key_data_dict[i] = data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0694c10-523c-47e3-af99-2ff2e91f61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in full_key_list: \n",
    "    iex_etf_stats = get_IEX_statistics(i)\n",
    "    #sharesOutstanding = iex_etf_stats['sharesOutstanding']   \n",
    "    full_key_data_dict[i]['Fundamentals']['sharesOutstanding'] = iex_etf_stats['sharesOutstanding']\n",
    "    full_key_data_dict[i]['Fundamentals']['peRatio'] = iex_etf_stats['peRatio']\n",
    "    full_key_data_dict[i]['Fundamentals']['beta'] = iex_etf_stats['beta']\n",
    "    full_key_data_dict[i]['Fundamentals']['week52high'] = iex_etf_stats['week52high']\n",
    "    full_key_data_dict[i]['Fundamentals']['week52low'] = iex_etf_stats['week52low']\n",
    "    full_key_data_dict[i]['Fundamentals']['week52change'] = iex_etf_stats['week52change']\n",
    "    full_key_data_dict[i]['Fundamentals']['avg10Volume'] = iex_etf_stats['avg10Volume']\n",
    "    full_key_data_dict[i]['Fundamentals']['avg30Volume'] = iex_etf_stats['avg30Volume']\n",
    "    full_key_data_dict[i]['Fundamentals']['marketcap_IEX'] = iex_etf_stats['marketcap']    \n",
    "    \n",
    "    ## Replace 'marketCap' and put into 'marketcap_FMP', then delete 'marketCap' to seperate sources\n",
    "    full_key_data_dict[i]['Fundamentals']['marketcap_FMP'] = full_key_data_dict[i]['Fundamentals']['marketCap']\n",
    "    del full_key_data_dict[i]['Fundamentals']['marketCap']\n",
    "    del full_key_data_dict[i]['Fundamentals']['price_earnings']\n",
    "    \n",
    "    full_key_data_dict[i]['iex_statistics'] = iex_etf_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c307f8b9-dd0b-475a-aae4-bdb45e3ee5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sharesOutstanding': 30626902,\n",
       " 'floatShares': 0,\n",
       " 'debt_ratio': 'debt_ratioValue',\n",
       " 'exchange': 'New York Stock Exchange Arca',\n",
       " 'final_close_price': 84.800003,\n",
       " 'peRatio': 0,\n",
       " 'beta': 0,\n",
       " 'week52high': 104.64,\n",
       " 'week52low': 70.33,\n",
       " 'week52change': 0.2356534775048127,\n",
       " 'avg10Volume': 394915,\n",
       " 'avg30Volume': 386220,\n",
       " 'marketcap_IEX': 2680620430,\n",
       " 'marketcap_FMP': 184056034}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_key_data_dict['ARKQ']['Fundamentals']\n",
    "#full_key_data_dict[test_symbol]['companyProfile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "906afecf-fb16-4df1-9fa4-c9e02f52afee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'AA',\n",
       " 'AAAU',\n",
       " 'AAL',\n",
       " 'AAOI',\n",
       " 'AAON',\n",
       " 'AAP',\n",
       " 'AAPL',\n",
       " 'AAU',\n",
       " 'AAWW',\n",
       " 'AB',\n",
       " 'ABB',\n",
       " 'ABBV',\n",
       " 'ABC',\n",
       " 'ABCL',\n",
       " 'ABEO',\n",
       " 'ABEV',\n",
       " 'ABG',\n",
       " 'ABM',\n",
       " 'ABMD',\n",
       " 'ABNB',\n",
       " 'ABOS',\n",
       " 'ABR',\n",
       " 'ABSI',\n",
       " 'ABT',\n",
       " 'ABUS',\n",
       " 'ACAD',\n",
       " 'ACB',\n",
       " 'ACC',\n",
       " 'ACCO',\n",
       " 'ACES',\n",
       " 'ACGL',\n",
       " 'ACHC',\n",
       " 'ACHV',\n",
       " 'ACI',\n",
       " 'ACIU',\n",
       " 'ACIW',\n",
       " 'ACLS',\n",
       " 'ACM',\n",
       " 'ACMR',\n",
       " 'ACN',\n",
       " 'ACOR',\n",
       " 'ACRE',\n",
       " 'ACRS',\n",
       " 'ACRX',\n",
       " 'ACST',\n",
       " 'ACVA',\n",
       " 'ACWI',\n",
       " 'ACXP',\n",
       " 'ADAP',\n",
       " 'ADBE',\n",
       " 'ADC',\n",
       " 'ADCT',\n",
       " 'ADES',\n",
       " 'ADGI',\n",
       " 'ADI',\n",
       " 'ADM',\n",
       " 'ADMA',\n",
       " 'ADMP',\n",
       " 'ADMS',\n",
       " 'ADNT',\n",
       " 'ADP',\n",
       " 'ADPT',\n",
       " 'ADS',\n",
       " 'ADSK',\n",
       " 'ADT',\n",
       " 'ADTX',\n",
       " 'ADUS',\n",
       " 'ADVM',\n",
       " 'ADX',\n",
       " 'ADXS',\n",
       " 'AEE',\n",
       " 'AEG',\n",
       " 'AEIS',\n",
       " 'AEL',\n",
       " 'AEM',\n",
       " 'AEO',\n",
       " 'AEP',\n",
       " 'AER',\n",
       " 'AERI',\n",
       " 'AES',\n",
       " 'AESE',\n",
       " 'AEZS',\n",
       " 'AFCG',\n",
       " 'AFG',\n",
       " 'AFIB',\n",
       " 'AFIN',\n",
       " 'AFL',\n",
       " 'AFMD',\n",
       " 'AFRM',\n",
       " 'AG',\n",
       " 'AGCO',\n",
       " 'AGE',\n",
       " 'AGEN',\n",
       " 'AGFY',\n",
       " 'AGG',\n",
       " 'AGI',\n",
       " 'AGIO',\n",
       " 'AGL',\n",
       " 'AGNC',\n",
       " 'AGQ',\n",
       " 'AGR',\n",
       " 'AGRI',\n",
       " 'AGRO',\n",
       " 'AGRX',\n",
       " 'AGS',\n",
       " 'AGTC',\n",
       " 'AGZ',\n",
       " 'AHH',\n",
       " 'AHPI',\n",
       " 'AHT',\n",
       " 'AIG',\n",
       " 'AIHS',\n",
       " 'AIM',\n",
       " 'AIMC',\n",
       " 'AIN',\n",
       " 'AIR',\n",
       " 'AIRC',\n",
       " 'AIV',\n",
       " 'AIZ',\n",
       " 'AJRD',\n",
       " 'AJX',\n",
       " 'AKA',\n",
       " 'AKAM',\n",
       " 'AKBA',\n",
       " 'AKRO',\n",
       " 'AKTS',\n",
       " 'AL',\n",
       " 'ALB',\n",
       " 'ALBO',\n",
       " 'ALC',\n",
       " 'ALDX',\n",
       " 'ALE',\n",
       " 'ALEC',\n",
       " 'ALEX',\n",
       " 'ALF',\n",
       " 'ALGM',\n",
       " 'ALGN',\n",
       " 'ALGS',\n",
       " 'ALGT',\n",
       " 'ALHC',\n",
       " 'ALK',\n",
       " 'ALKT',\n",
       " 'ALL',\n",
       " 'ALLE',\n",
       " 'ALLO',\n",
       " 'ALLT',\n",
       " 'ALLY',\n",
       " 'ALNA',\n",
       " 'ALNY',\n",
       " 'ALRM',\n",
       " 'ALSN',\n",
       " 'ALT',\n",
       " 'ALVR',\n",
       " 'ALXO',\n",
       " 'ALZN',\n",
       " 'AM',\n",
       " 'AMAT',\n",
       " 'AMBA',\n",
       " 'AMBP',\n",
       " 'AMC',\n",
       " 'AMCR',\n",
       " 'AMCX',\n",
       " 'AMD',\n",
       " 'AME',\n",
       " 'AMED',\n",
       " 'AMG',\n",
       " 'AMGN',\n",
       " 'AMH',\n",
       " 'AMJ',\n",
       " 'AMKR',\n",
       " 'AMLP',\n",
       " 'AMN',\n",
       " 'AMP',\n",
       " 'AMPE',\n",
       " 'AMPL',\n",
       " 'AMPY',\n",
       " 'AMRC',\n",
       " 'AMRN',\n",
       " 'AMRS',\n",
       " 'AMRX',\n",
       " 'AMSC',\n",
       " 'AMT',\n",
       " 'AMWL',\n",
       " 'AMX',\n",
       " 'AMZA',\n",
       " 'AMZN',\n",
       " 'AN',\n",
       " 'ANET',\n",
       " 'ANF',\n",
       " 'ANGI',\n",
       " 'ANGL',\n",
       " 'ANIX',\n",
       " 'ANSS',\n",
       " 'ANTM',\n",
       " 'AOA',\n",
       " 'AOK',\n",
       " 'AOM',\n",
       " 'AON',\n",
       " 'AOR',\n",
       " 'AOS',\n",
       " 'APA',\n",
       " 'APAM',\n",
       " 'APD',\n",
       " 'APH',\n",
       " 'APLE',\n",
       " 'APLS',\n",
       " 'APO',\n",
       " 'APP',\n",
       " 'APPF',\n",
       " 'APPN',\n",
       " 'APPS',\n",
       " 'APR',\n",
       " 'APRN',\n",
       " 'APTS',\n",
       " 'APTV',\n",
       " 'APTX',\n",
       " 'AQMS',\n",
       " 'AQN',\n",
       " 'AQST',\n",
       " 'AQUA',\n",
       " 'AR',\n",
       " 'ARAV',\n",
       " 'ARAY',\n",
       " 'ARBK',\n",
       " 'ARCB',\n",
       " 'ARCH',\n",
       " 'ARCO',\n",
       " 'ARCT',\n",
       " 'ARDX',\n",
       " 'ARE',\n",
       " 'ARES',\n",
       " 'ARI',\n",
       " 'ARIS',\n",
       " 'ARKF',\n",
       " 'ARKG',\n",
       " 'ARKK',\n",
       " 'ARKQ',\n",
       " 'ARKW',\n",
       " 'ARKX',\n",
       " 'ARLO',\n",
       " 'ARLP',\n",
       " 'ARMK',\n",
       " 'ARNA',\n",
       " 'AROC',\n",
       " 'ARR']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f516c-b017-4610-86c8-8ba08fcd07a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
