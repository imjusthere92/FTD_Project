{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e05a692-4c5e-490a-9527-cd9f28b56181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import quandl\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d8f201-1904-4bd5-93fa-6fa89fc8c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants \n",
    "\n",
    "## Set start date variable - dataframes will be created starting from this date\n",
    "start_date = '2016-01-01'\n",
    "end_date = '2021-12-31'\n",
    "default_date_range = '71m' ## Default Range for IEX functions - don't need more at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c84aaab-7cfe-4045-bf07-f60150266539",
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUANDL/NASDAQ \n",
    "nsdq_api_key = os.environ.get('NASDAQ_API_KEY')\n",
    "base_url_nsdq = 'https://data.nasdaq.com/api/v3/datasets/FINRA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9b1019-8417-42b3-b4a9-6ee72cb5654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use pickle module to import and export and save files\n",
    "import pickle\n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "def save_obj(obj, path ):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a100c029-82b5-4b39-a710-21103d95e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Short \"Interest\" Data from Quandl \n",
    "def get_short_data_QUANDL(symbol):\n",
    "    string_nsdq = \"FINRA/FNSQ_\"+symbol\n",
    "    string_nyse = \"FINRA/FNYX_\"+symbol\n",
    "    \n",
    "    df1 = quandl.get(string_nsdq,start_date=start_date,end_date=end_date,authtoken=nsdq_api_key)   ## Nasdaq\n",
    "    df2 = quandl.get(string_nyse,start_date=start_date,end_date=end_date,authtoken=nsdq_api_key)   ## NYSE\n",
    "\n",
    "    df1 = df1.rename(columns={'ShortVolume':'ShortVolumeNSDQ','TotalVolume':'TotalVolumeNSDQ'})\n",
    "    #df1 = df1.drop(columns={'ShortExemptVolume'})\n",
    "    df1 = df1.rename(columns={'ShortExemptVolume':'ShortExemptVolumeNSDQ'})\n",
    "\n",
    "    df2 = df2.rename(columns={'ShortVolume':'ShortVolumeNYSE','TotalVolume':'TotalVolumeNYSE'})\n",
    "    #df2 = df2.drop(columns={'ShortExemptVolume'})\n",
    "    df2 = df2.rename(columns={'ShortExemptVolume':'ShortExemptVolumeNYSE'})\n",
    "\n",
    "    df3 = pd.merge(df1,df2,on='Date',how='outer')\n",
    "    #df3 = df3.fillna(0)\n",
    "    \n",
    "    return df3\n",
    "\n",
    "\n",
    "## Return FTD Data from SEC FTD files using a Stock's CUSIP number to sort \n",
    "def return_ftd_data_cusip(cusip_number):\n",
    "    df = ftd_df.copy()\n",
    "    df.set_index(\"CUSIP\",inplace=True)\n",
    "    df = df.loc[cusip_number]\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.set_index('Date')\n",
    "    return df\n",
    "\n",
    "## Return the CUSIP symbol from the symbol_df symbol list \n",
    "def return_CUSIP_from_symbol(symbol):\n",
    "    df = symbol_df.copy()\n",
    "    df.set_index('SYMBOL',inplace=True)\n",
    "    cusip_variable = df.loc[symbol]\n",
    "    cusip_variable = cusip_variable['CUSIP']\n",
    "    return cusip_variable\n",
    "\n",
    "def return_ftd_data_symbol(symbol):\n",
    "    cusip_number = return_CUSIP_from_symbol(symbol)\n",
    "    df = return_ftd_data_cusip(cusip_number)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004def6e-e654-48dd-9daa-579906cd6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FMP Constants \n",
    "fmpbase_urlv3 = 'https://fmpcloud.io/api/v3/'\n",
    "fmpbase_urlv4 = 'https://fmpcloud.io/api/v4/'\n",
    "api_key = os.getenv(\"FMP_CLOUD_API_KEY\")\n",
    "\n",
    "## FMP Functions \n",
    "def get_FMP_historical_data(symbol, startDate=start_date, endDate=end_date, apiKey=api_key):\n",
    "    url_hist_price = fmpbase_urlv3+'historical-price-full/'\n",
    "    url_hist_query_with_date = url_hist_price+symbol+'?from='+startDate+'&to='+endDate+'&apikey='+apiKey\n",
    "    resp_data = requests.get(url_hist_query_with_date)\n",
    "    json_ = resp_data.json()\n",
    "    data = json_['historical']\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={'date':'Date'},inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.reindex(index=df.index[::-1]) ## Reverse the DataFrame \n",
    "    df.set_index('Date',inplace=True)\n",
    "    df.drop(columns='label',inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_float_data_FMP(symbol):\n",
    "    url_float_shares = fmpbase_urlv4+'shares_float?symbol='\n",
    "    url_query_float_data = url_float_shares+symbol+'&apikey='+api_key\n",
    "    resp_data = requests.get(url_query_float_data)\n",
    "    #df = pd.DataFrame(resp_data.json())\n",
    "    json_ = resp_data.json()\n",
    "    return json_[0]\n",
    "\n",
    "def get_company_profile_FMP_json(symbol):\n",
    "    ## https://fmpcloud.io/api/v3/profile/AAPL?apikey='yourkeyhere'\n",
    "    url_company_profile_url = fmpbase_urlv3+'profile/'+symbol+'?apikey='+api_key\n",
    "    resp_data = requests.get(url_company_profile_url)\n",
    "    json_response = resp_data.json()\n",
    "    return json_response[0]\n",
    "\n",
    "# def save_and_export_raw_df_csv(data, symbol, path='None'):\n",
    "#     ## Can set custom path (useful for testing) otherwise will default to below path\n",
    "#     if path=='None':\n",
    "#         path = ('../FilesExportIndividualStockDFs_Big/'+symbol+'_combined_df.csv')\n",
    "#     data.to_csv(path)\n",
    "    \n",
    "def save_and_export_raw_df_pkl(data, symbol, path='None'):\n",
    "    ## Can set custom path (useful for testing) otherwise will default to below path\n",
    "    if path=='None':\n",
    "        path = ('../FilesExport_TimeSeries_DFs/'+symbol+'_combined_df.pkl')\n",
    "    save_obj(data,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2be0b1b-be26-4e5a-959e-480fdd9807a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_series_data(symbol):\n",
    "    ftd_data = return_ftd_data_symbol(symbol)\n",
    "    ftd_data = ftd_data.drop(columns={'SYMBOL'})\n",
    "\n",
    "    fmp_data = get_FMP_historical_data(symbol)\n",
    "    df1 = pd.merge(fmp_data,ftd_data, on='Date',how='outer')\n",
    "    df1['QUANTITY_FAILS'] = df1['QUANTITY_FAILS'].fillna(0)\n",
    "    df1['volume'] = df1['volume'].fillna(0)\n",
    "    df1['unadjustedVolume'] = df1['unadjustedVolume'].fillna(0)\n",
    "    df1['vwap'] = df1['vwap'].fillna(0)\n",
    "    df2 = get_short_data_QUANDL(symbol)\n",
    "    df = pd.merge(df1,df2,on='Date',how='outer')\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d72aee8-d91a-42ff-b8b0-a31a036f4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Import FTD File using CSV \n",
    "# ftd_df = pd.read_csv(\n",
    "#     Path('../Resources/ftd_all_data.csv'),\n",
    "#     index_col=0, parse_dates=True\n",
    "# )\n",
    "# ## Import Symbol and CUSIP list using CSV\n",
    "# symbol_df = pd.read_csv(\n",
    "#     Path('../Resources/symbol_all_list.csv'),\n",
    "#     index_col=0\n",
    "# )\n",
    "\n",
    "\n",
    "## Import dataframe objects using Pickle \n",
    "ftd_df = load_obj('../Resources/ftd_all_data.pkl')\n",
    "symbol_df = load_obj('../Resources/symbol_all_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7135d89b-e904-41ed-9ee3-7a07a290b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite loop to access FMP data using list of symbols from symbol_df \n",
    "## This code is written this way, with the while loop, because it allows you to pick up from close to\n",
    "## where you left off, in the event of an API failure, or the code stopping. \n",
    "## Changing the x and y starting values will allow you to pick up from where the loop failed, and continue\n",
    "## reading data. \n",
    "\n",
    "## Create while loop that access FMP and gets data \n",
    "x = 0    \n",
    "y = 50\n",
    "increment = 50  ## Make sure increment is right\n",
    "\n",
    "## Setup in 50 increments to find error in case the loop fails, but keep previous data.\n",
    "\n",
    "# ## Initialize lists for successful calls\n",
    "# symbol_success_list = []\n",
    "# symbol_not_success_list = [] \n",
    "\n",
    "length_ = len(symbol_df)\n",
    "test_length = 200 \n",
    "loop_length = length_ ## Set to length_ to run as full, or your test_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6272aae-6e56-48fb-8c73-1e2a56a04abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reimport lists \n",
    "symbol_success_list = load_obj('../Resources/02_symbol_success_list.pkl')\n",
    "len(symbol_success_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbc102f3-8101-4177-bc84-0055c504b5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4410"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_not_success_list = load_obj('../Resources/02_symbol_not_success_list.pkl')\n",
    "len(symbol_not_success_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d25e17-ed8d-4f66-b790-8e2c295dda01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LL'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#symbol_export_list[3497]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "598354e5-9455-40be-84d8-88794c0d70a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMDXW\n",
      "18794\n"
     ]
    }
   ],
   "source": [
    "## Code to locate index of symbol \n",
    "test_symbol = 'LMDXW'\n",
    "\n",
    "length_ = len(symbol_df)\n",
    "index_variable = 0 \n",
    "\n",
    "for i in range(length_):\n",
    "    if symbol_df['SYMBOL'].iloc[i] == test_symbol:\n",
    "        index_variable = i\n",
    "        print(symbol_df['SYMBOL'].iloc[i])\n",
    "        print(index_variable)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27238c82-83a8-4902-866f-667cf6885c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 18794    \n",
    "y = x + 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31408711-1dca-4cb8-a2a0-8a31f24540ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "while (x < loop_length):\n",
    "\n",
    "    ## Set y value for end of while loop\n",
    "    if y >= length_: y = length_\n",
    "    ## In theory this should stop the for loop from crashing \n",
    "    ##    at the end and running out of index range     \n",
    "    \n",
    "    range_var = range(x,y)\n",
    "    ## Set label variables for exports \n",
    "    str_symbol1 = str(x)\n",
    "    y2 = y - 1 \n",
    "    str_symbol2 = str(y2)\n",
    "    \n",
    "    for i in range_var: \n",
    "        \n",
    "        ## Create temp lists \n",
    "        temp_symbol_success_list = []\n",
    "        temp_symbol_not_success_list = []\n",
    "        \n",
    "        ## Iterate through symbol list and create data by symbol\n",
    "        symbol_var = symbol_df['SYMBOL'][i]\n",
    "        \n",
    "        # Use while running loop, if error is made, can see what index it happened on \n",
    "        # can also check current value of symbol_var as well \n",
    "        error_var = i\n",
    "        \n",
    "        ## Get Time Series Data \n",
    "        try:\n",
    "            time_series_df = get_time_series_data(symbol_var)\n",
    "            ## Export as a list with a key (the stock symbol) to the dataframe \n",
    "            export_obj = [{symbol_var:time_series_df}]\n",
    "            \n",
    "            if len(time_series_df) > 1500:\n",
    "                symbol_success_list.append(symbol_var)\n",
    "            else:\n",
    "                symbol_not_success_list.append(symbol_var)               \n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        ## If successful, export data \n",
    "        save_and_export_raw_df_pkl(export_obj,symbol_var)\n",
    "            \n",
    "    ## If for loop successful, append temp_symbol lits to main lists \n",
    "    symbol_success_list.extend(temp_symbol_success_list)\n",
    "    symbol_not_success_list.extend(temp_symbol_not_success_list)\n",
    "    \n",
    "    ## Export main lists each time, and rewrite during each iteration of while loop \n",
    "    ## Can read in list afterwards, to figure out where loop went wrong, and where to restart \n",
    "    save_obj(symbol_success_list,'../Resources/02_symbol_success_list.pkl')\n",
    "    save_obj(symbol_not_success_list,'../Resources/02_symbol_not_success_list.pkl')\n",
    "    \n",
    "    ## Check before run, if incorrect, can waste a lot of API credits  \n",
    "    x += increment\n",
    "    y += increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc79735-8042-48aa-b971-89507a31f6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
