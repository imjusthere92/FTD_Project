{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7b87db-e1f0-4e0a-9003-b27cbf8d4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import glob\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72193e0-b240-43ed-97cc-6307a514f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine-learning specific imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94480e2-8211-47ff-9b7b-636027857c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pickle for exports and imports of data  \n",
    "import pickle \n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj, path ):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef149ed6-8d17-4275-aa0f-187cefe5c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## API Imports \n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "## FMP Constants \n",
    "fmpbase_urlv3 = 'https://fmpcloud.io/api/v3/'\n",
    "fmpbase_urlv4 = 'https://fmpcloud.io/api/v4/'\n",
    "api_key = os.getenv(\"FMP_CLOUD_API_KEY\")\n",
    "\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-01-31'\n",
    "\n",
    "## FMP Functions \n",
    "def get_FMP_historical_data(symbol, startDate=start_date, endDate=end_date, apiKey=api_key):\n",
    "    url_hist_price = fmpbase_urlv3+'historical-price-full/'\n",
    "    url_hist_query_with_date = url_hist_price+symbol+'?from='+startDate+'&to='+endDate+'&apikey='+apiKey\n",
    "    resp_data = requests.get(url_hist_query_with_date)\n",
    "    json_ = resp_data.json()\n",
    "    data = json_['historical']\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={'date':'Date'},inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.reindex(index=df.index[::-1]) ## Reverse the DataFrame \n",
    "    df.set_index('Date',inplace=True)\n",
    "    df.drop(columns='label',inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac9ded4-e74c-4f40-929c-5fdbcf754bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_data(symbol):\n",
    "    path = Path('../FilesExport_Updated_DFs_01_31/'+symbol+'_ti_df_no_ftd.pkl')\n",
    "    data = load_obj(path)\n",
    "    df = data[symbol]\n",
    "    \n",
    "    df_close = df[['close']]\n",
    "    df_close = df_close.reset_index().rename(columns={\"Date\": \"Close_Date\"})\n",
    "    \n",
    "    features_df = df.reset_index().drop(columns=['close','adjClose'])\n",
    "    \n",
    "    #new_close_df = df_close.iloc[n_days: , :].reset_index(drop=True)\n",
    "    \n",
    "    ## Prevent multiple API calls each time, but use API when needed. \n",
    "    try:\n",
    "        path = Path('../FilesExport_Updated_API_data/'+symbol+'_jan_2022.pkl')\n",
    "        api_df = load_obj(path)\n",
    "    except:\n",
    "        api_df = get_FMP_historical_data(symbol)\n",
    "    \n",
    "\n",
    "    new_data = api_df[['close']]\n",
    "    new_data = new_data.reset_index().rename(columns={\"Date\": \"Close_Date\"})\n",
    "    #new_data = new_data.iloc[0:n_days]\n",
    "    \n",
    "    new_close_df = df_close.append(new_data, ignore_index=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    return features_df, new_close_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd97866c-c3b2-4774-9d60-67915a06874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(symbol):\n",
    "    path = Path('../FilesExport_Complete_DFs_TI_noShift/'+symbol+'_TI_DF_no_shift.pkl')\n",
    "    data = load_obj(path)\n",
    "    df = data[symbol]\n",
    "\n",
    "    df_close = df[['close']]\n",
    "    df_close = df_close.reset_index().rename(columns={\"Date\": \"Close_Date\"})\n",
    "\n",
    "    features_df = df.reset_index().drop(columns=['close','adjClose'])   \n",
    "    \n",
    "    return features_df, df_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c659cdc4-1cfa-47a4-8a34-0b7f93289e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_data_transform(x_data, y_data, num_steps=5):\n",
    "    \"\"\" Changes data to the format for LSTM training \n",
    "for sliding window approach \"\"\"\n",
    "    # Prepare the list for the transformed data\n",
    "    X, y = list(), list()\n",
    "    # Loop of the entire data set\n",
    "    for i in range(x_data.shape[0]):\n",
    "        # compute a new (sliding window) index\n",
    "        end_ix = i + num_steps\n",
    "        # if index is larger than the size of the dataset, we stop\n",
    "        if end_ix >= x_data.shape[0]:\n",
    "            break\n",
    "        # Get a sequence of data for x\n",
    "        seq_X = x_data[i:end_ix]\n",
    "        # Get only the last element of the sequency for y\n",
    "        seq_y = y_data[end_ix]\n",
    "        # Append the list with sequencies\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "    # Make final arrays\n",
    "    x_array = np.array(X)\n",
    "    y_array = np.array(y)\n",
    "    return x_array, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e9464f-62e6-4abf-b10e-f37851c7cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_predict_model(symbol):\n",
    "    import_path='../Model_Data/LSTM_Model_Data_1/'\n",
    "    model_type = 'LSTM'\n",
    "    #n_days_string = str(n_days)\n",
    "    import_path_prefix = import_path+symbol+'_'+model_type\n",
    "\n",
    "    file_path = Path(import_path_prefix+'_model_data.json')\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    loaded_model = model_from_json(model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    file_path = Path(import_path_prefix+'_model_weights.h5')\n",
    "    loaded_model.load_weights(file_path)\n",
    "\n",
    "    ## Load model summary \n",
    "    file_path = Path(import_path_prefix+'_model_results.pkl')\n",
    "    model_summary = load_obj(file_path)\n",
    "\n",
    "    #pred_df = model_summary['prediction_df']\n",
    "\n",
    "    time_step = model_summary['num_time_steps']\n",
    "\n",
    "    new_features, new_close = get_data(symbol)\n",
    "\n",
    "\n",
    "    X = new_features.set_index('Date')\n",
    "    y = new_close.set_index('Close_Date')\n",
    "\n",
    "    split_var = 0.9\n",
    "\n",
    "    ## Split data\n",
    "    split = int(split_var * len(X))\n",
    "    x_train = X[: split]\n",
    "    x_test = X[split:]\n",
    "    y_train = y[: split]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    ## Scale data \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    x_train_sc = scaler_x.fit_transform(x_train)\n",
    "    x_test_sc = scaler_x.transform(x_test)\n",
    "    y_train_sc = scaler_y.fit_transform(y_train)\n",
    "    y_test_sc = scaler_y.transform(y_test)\n",
    "\n",
    "    num_steps = time_step\n",
    "    # training set\n",
    "    (x_train_transformed,\n",
    "     y_train_transformed) = lstm_data_transform(x_train_sc, y_train_sc, num_steps=num_steps)\n",
    "    assert x_train_transformed.shape[0] == y_train_transformed.shape[0]\n",
    "    # test set\n",
    "    (x_test_transformed,\n",
    "     y_test_transformed) = lstm_data_transform(x_test_sc, y_test_sc, num_steps=num_steps)\n",
    "    assert x_test_transformed.shape[0] == y_test_transformed.shape[0]\n",
    "    \n",
    "    test_predict = loaded_model.predict(x_test_transformed)\n",
    "    \n",
    "    ## Attempt inverse transform \n",
    "    predicted_prices = scaler_y.inverse_transform(test_predict)\n",
    "    real_prices = scaler_y.inverse_transform(y_test_transformed)\n",
    "\n",
    "    prediction_df = pd.DataFrame({\n",
    "        'Actual':real_prices.ravel(),\n",
    "        'Prediction':predicted_prices.ravel()\n",
    "    })\n",
    "    \n",
    "    model_data_dict = {}\n",
    "    \n",
    "    model_data_dict[symbol] = {\n",
    "        'prediction_df':prediction_df,\n",
    "        'model_summary':model_summary\n",
    "    }\n",
    "\n",
    "    return model_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82b6d247-2407-45ba-951e-78b1d5ef4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol = 'GME'\n",
    "# days_to_plot = 60\n",
    "\n",
    "# model_data = load_and_predict_model(symbol)\n",
    "\n",
    "# #new_pred_df[['Actual','Prediction']].tail(days_to_plot).plot(use_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68fd1ab6-2056-4124-baeb-61df2364fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_summary = model_data[symbol]['model_summary']\n",
    "# model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b6c96f-90ab-4c8a-b711-24588d71a855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import\n",
    "path = Path('../Resources/LSTM_model_acc_dict_1.pkl')\n",
    "symbol_list = load_obj(path)\n",
    "len(symbol_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25204413-4e13-42f3-901c-527905876730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AYTU</th>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTP</th>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSHG</th>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPTH</th>\n",
       "      <td>0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CYCC</th>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDS</th>\n",
       "      <td>34.695141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTNR</th>\n",
       "      <td>65.813507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAR</th>\n",
       "      <td>82.900650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEHR</th>\n",
       "      <td>157.603210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LWLG</th>\n",
       "      <td>1159.224731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>770 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc_score\n",
       "AYTU     0.000158\n",
       "MTP      0.000178\n",
       "PSHG     0.000194\n",
       "BPTH     0.000280\n",
       "CYCC     0.000297\n",
       "...           ...\n",
       "DDS     34.695141\n",
       "VTNR    65.813507\n",
       "CAR     82.900650\n",
       "AEHR   157.603210\n",
       "LWLG  1159.224731\n",
       "\n",
       "[770 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = pd.DataFrame.from_dict(symbol_list,orient='index')\n",
    "acc_df.sort_values('acc_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ae9ad-f817-44ca-afd6-3d45afd5d34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
