{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f767257-d80a-4f44-99cf-22be359be56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file will have all the functions needed to load, view, and evaluate any saved models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c383c62e-e840-4200-8e14-db2434a0656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de74192-bb03-47d4-937f-ef7fce68c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine-learning specific imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7146d4-d545-415d-847d-e59c82c4eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pickle for exports and imports of data  \n",
    "import pickle \n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj, path ):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8998d9ee-1a6c-4da2-b1ed-c651d54784b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are five folders with useful model data that will be used for the project presentation\n",
    "## All located in '../Model_Data/'\n",
    "\n",
    "## There are two sets of Neural Network (NN) models which are direct improvements upon the original machine-learning \n",
    "## models from FTD_Project_2. The difference between each set, which should be obvious from the title path, is one set \n",
    "## of models was trained with and including the SEC's FTD data, while the second set had the FTD data omitted from the \n",
    "## models. Each model is improved relative to FTD_Project_2, because now they not only attempt to predict the close \n",
    "## price with the data provided, but now they attempt to forecast the close price 1, 2, 5, or 10 days in advance. \n",
    "\n",
    "## Model locations: \n",
    "## Model_1: \n",
    "# path_1 = Path('../Model_Data/Date_Test_NN_noFTD_all/')   ## Contains models trained without FTD data\n",
    "## Model_2: \n",
    "# path_2 = Path('../Model_Data/Date_Test_NN_w_FTD_all/')   ## Contains models trained with FTD data \n",
    "\n",
    "\n",
    "\n",
    "## The third set of models shares a similarity with the previous two NN models - it used the same dataset (up to Dec31st)\n",
    "## to train, however, instead of a neural network (NN) model, it is an LSTM model designed to supplement the performance\n",
    "## of the NN models and compare its results alongside. \n",
    "## This third model does not predict/forecast data in quite the same way as the NN models - it should be used as a \n",
    "## comparison or addition to the 1-day NN models listed above. \n",
    "## It also acts as demonstration that LSTM-models can also be used, in addition to NN, to predict/track the closing price\n",
    "## using our FTD, Short Interest, and Historical Pricing dataset. \n",
    "\n",
    "## Model Location:\n",
    "## Model_3: \n",
    "# path_3 = Path('../Model_Data/LSTM_Model_Data_1/')  ## Contains LSTM models trained with FTD data, up to Dec31st. \n",
    "\n",
    "\n",
    "\n",
    "## The fourth set of models were designed after early evaluations of models _1 and _2. The purpose of the first \n",
    "## two models was to compare the effect of removing the FTD Data from the features of the machine learning model, \n",
    "## and early evaluations showed that, while definitely improving the accuracy of the models when included, the \n",
    "## FTD data was not necessary or required in order to achieve accurate price tracking / predictions. \n",
    "## So, the fourth (and fifth) models were designed as concept of how these models could genuinely be used to \n",
    "## make predictions, select stock symbols, plan a buying strategy, and actually trade using these models that \n",
    "## have been created over the course of this project. \n",
    "\n",
    "## Model Location:\n",
    "# Model_4:\n",
    "# path_4 = Path('../Model_Data/Feb2022_NN_models/') ## Contians NN models, capable of taking January's data and making\n",
    "                                                    ## predictions 1, 2, 5, or 10 trading days into February. \n",
    "    \n",
    "## The fifth set of models were created for the same purpose as the fourth, and perform a 10-day forecast of close price \n",
    "## for a given stock. Instead of a NN model, this is an improved-upon (relative to Model_3) LSTM model that alongside \n",
    "## our NN can be used to forecast stock price predictions, with enough accuracy that one could consider trading off \n",
    "## of these models. \n",
    "\n",
    "## Model Location:\n",
    "# Model_5:\n",
    "# path_5 = Path('../Model_Data/Feb2022_LSTM_models_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b1de87-ccf3-493a-99b2-6f3e826ca0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
